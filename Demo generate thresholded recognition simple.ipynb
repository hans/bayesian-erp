{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c36a3ae-7fdc-4b6e-b787-a9944f44bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import tensor as T\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcfd4b0-1d87-43c7-9d22-155b7717cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONOPTIMIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1019e0-9fd6-4925-a2c0-72bf5fcbd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a667bfeb-e8d2-4f96-8371-3060f7cc4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STIM_SOURCE = \"random\"\n",
    "STIM_SOURCE = \"sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85cfa55-45a4-4dd9-859e-8f1da39936db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from berp.generators import stimulus\n",
    "from berp.generators.response import simple_gaussian\n",
    "import berp.generators.thresholded_recognition_simple as gen\n",
    "import berp.models.reindexing_regression as rr\n",
    "from berp.util import gaussian_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb433a2-1eaa-46ae-bd5e-e2fcbb0f60ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCritical parameters:\u001b[0m\n",
      "Threshold:\t 0.17194396257400513\n",
      "Noise sigma:\t 5.0\n"
     ]
    }
   ],
   "source": [
    "# Establish parameters used to synthesize data\n",
    "# Obviously these will not be used during inference!\n",
    "\n",
    "coef_mean = torch.tensor([-1.])\n",
    "params = rr.ModelParameters(\n",
    "    lambda_=torch.tensor(1.0),\n",
    "    confusion=gen.phoneme_confusion,\n",
    "    threshold=torch.distributions.Beta(1.2, 1.2).sample(),\n",
    "\n",
    "    # NB only used for generation, not in model\n",
    "    a=torch.tensor(0.2),\n",
    "    b=torch.tensor(0.1),\n",
    "    coef=coef_mean,\n",
    "    sigma=torch.tensor(5.0),\n",
    ")\n",
    "\n",
    "print(f\"{Style.BRIGHT}Critical parameters:{Style.RESET_ALL}\")\n",
    "print(\"Threshold:\\t\", params.threshold.item())\n",
    "print(\"Noise sigma:\\t\", params.sigma.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02c3b64-e893-43f3-9746-cd218f7b3f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "WARNING:root:Tokenizer is missing pad token; using EOS token <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "if STIM_SOURCE == \"random\":\n",
    "    stim_gen = stimulus.RandomStimulusGenerator()\n",
    "elif STIM_SOURCE == \"sentences\":\n",
    "    text = \"\"\"\n",
    "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n",
    "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
    "\"\"\".strip()\n",
    "    # sentences = [s.strip().replace(\"\\n\", \"\") for s in re.split(r\"[.?!]\", text)]\n",
    "    # sentences = [s for s in sentences if s]\n",
    "    \n",
    "    phonemes = np.array(list(\"abcdefghijklmnopqrstuvwxyz_\"))\n",
    "    stim_gen = stimulus.NaturalLanguageStimulusGenerator(\n",
    "        phonemes=phonemes, hf_model=\"gpt2\",\n",
    "        phonemizer=None, num_candidates=1000, batch_size=8)\n",
    "    \n",
    "    tokenizer = stim_gen.processor._tokenizer\n",
    "    tokenized = tokenizer(text)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenizer(text).input_ids)\n",
    "    token_to_word = dict(enumerate(tokenized.word_ids()))\n",
    "    word_to_token = defaultdict(list)\n",
    "    for token, word in token_to_word.items():\n",
    "        word_to_token[word].append(token)\n",
    "    \n",
    "    # TODO\n",
    "    word_features = {word_id: torch.zeros(1) for word_id in word_to_token}\n",
    "    \n",
    "    stim_gen = partial(stim_gen, tokens, word_features, word_to_token, ground_truth_phonemes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd99002a-ea72-4ed1-bd35-c6c8c913b945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34038c8e5694b329b7c1acc872215a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/vast-storage.ib.cluster/scratch/vast/cpl/jgauthie/scratch/bayesian-erp/berp/generators/response.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signal = torch.tensor(signal)\n"
     ]
    }
   ],
   "source": [
    "ds = gen.sample_dataset(params, stim_gen, response_type=\"n400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3bbfdd-9c95-439e-99a3-a4c8e8142ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_candidates = rr.predictive_model(ds.p_word, ds.candidate_phonemes, confusion=params.confusion, lambda_=params.lambda_,\n",
    "                                   return_gt_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d7a8419-35c6-475f-826f-87ba96ee7e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd368d78a7540d589eac80b80a801fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def get_topk(row, k=3):\n",
    "#     return row[(-row).argsort()[:k]]\n",
    "\n",
    "plot_data = []\n",
    "k = 1000\n",
    "for p_candidates_i, candidates, gt_length in zip(tqdm(p_candidates), ds.candidate_phonemes, ds.word_lengths):\n",
    "    candidate_strs = [\"\".join(ds.phonemes[idx.item()].rstrip(\"_\") for idx in word)\n",
    "                      for word in candidates]\n",
    "    plot_data_i = []\n",
    "    \n",
    "    p_candidates_i = p_candidates_i.T.numpy()[:gt_length]\n",
    "    topk = (-p_candidates_i).argsort(1)[:, :k]\n",
    "    p_candidates_i = np.take_along_axis(p_candidates_i, topk, 1)\n",
    "    for t, (p_candidates_t, candidates_t) in enumerate(zip(p_candidates_i, topk)):\n",
    "        plot_data_i.append((candidate_strs[0][:t + 1], list(zip(p_candidates_t, [candidate_strs[idx] for idx in candidates_t]))))\n",
    "        \n",
    "    plot_data.append(plot_data_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8774fda3-1930-4b19-8fd6-1106a308e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"plot_Data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(plot_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60fef3d1-f3b3-40ef-9e5f-158840e7b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.animation:MovieWriter stderr:\n",
      "[libopenh264 @ 0x565426f7d380] Incorrect library version loaded\n",
      "Error initializing output stream 0:0 -- Error while opening encoder for output stream #0:0 - maybe incorrect parameters such as bit_rate, rate, width or height\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '432x288', '-pix_fmt', 'rgba', '-r', '20.0', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'h264', '-pix_fmt', 'yuv420p', '-y', 'test.m4v']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:236\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:1095\u001b[0m, in \u001b[0;36mAnimation.save\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         frame_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1095\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrab_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msavefig_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:353\u001b[0m, in \u001b[0;36mMovieWriter.grab_frame\u001b[0;34m(self, **savefig_kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Save the figure data to the sink, using the frame format and dpi.\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msavefig_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/figure.py:3019\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3016\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3017\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2319\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(arg)\n\u001b[0;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:412\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     warn_deprecated(\n\u001b[1;32m    406\u001b[0m         since,\n\u001b[1;32m    407\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:486\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_raw\u001b[0;34m(self, filename_or_obj, *args)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39mopen_file_cm(filename_or_obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m--> 486\u001b[0m     \u001b[43mfh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manimation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FuncAnimation\n\u001b[1;32m     13\u001b[0m anim \u001b[38;5;241m=\u001b[39m FuncAnimation(fig, anim, blit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.m4v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:1095\u001b[0m, in \u001b[0;36mAnimation.save\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         progress_callback(frame_number, total_frames)\n\u001b[1;32m   1094\u001b[0m         frame_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1095\u001b[0m writer\u001b[38;5;241m.\u001b[39mgrab_frame(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msavefig_kwargs)\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:238\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:344\u001b[0m, in \u001b[0;36mMovieWriter.finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m     overridden_cleanup()\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om2/miniconda/envs/berp/lib/python3.9/site-packages/matplotlib/animation.py:375\u001b[0m, in \u001b[0;36mMovieWriter._cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _log\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    372\u001b[0m         logging\u001b[38;5;241m.\u001b[39mWARNING \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;28;01melse\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mDEBUG,\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieWriter stderr:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, err)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mreturncode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39margs, out, err)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '432x288', '-pix_fmt', 'rgba', '-r', '20.0', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'h264', '-pix_fmt', 'yuv420p', '-y', 'test.m4v']' returned non-zero exit status 1."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "# barplot = plt.bar([\"\"] * 3, [0] * 3)\n",
    "\n",
    "def anim(i):\n",
    "    incremental_text, dist = plot_data[i]\n",
    "    xs = [word for _, word in dist]\n",
    "    ys = [prob for prob, _ in dist]\n",
    "    print(i)\n",
    "    return plt.bar(xs, ys)\n",
    "    \n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "anim = FuncAnimation(fig, anim, blit=True, repeat=True, frames=5, interval=50)\n",
    "anim.save(\"test.m4v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714b8ce-394d-464c-b6fc-87a687594d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = simple_gaussian(params.b, params.a, ds.sample_rate)\n",
    "ys = params.coef[-1] * ys\n",
    "plt.plot(xs, ys)\n",
    "\n",
    "plt.title(\"Characteristic response in synthetic dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4c8fd-9cb2-4da8-aeb4-bb8a91f5908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_word_posterior = rr.predictive_model(ds.p_word, ds.candidate_phonemes, confusion=params.confusion, lambda_=params.lambda_)\n",
    "recognition_points = rr.recognition_point_model(p_word_posterior, ds.word_lengths, threshold=params.threshold)\n",
    "recognition_onsets = torch.gather(ds.phoneme_onsets, 1,\n",
    "                                  recognition_points.unsqueeze(1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccaaca6-2a64-4c70-ae40-d7d7ebc4ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_gt_probabilities = rr.predictive_model(ds.p_word, ds.candidate_phonemes, confusion=params.confusion, lambda_=params.lambda_)\n",
    "incremental_gt_probabilities[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1c7d5-0886-4d35-8529-3092883ac863",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 7))\n",
    "ax.plot(np.arange(ds.Y.shape[0]) / ds.sample_rate, ds.Y[:, 0], alpha=0.5)\n",
    "\n",
    "annot_height = ax.get_ylim()[0] + 1\n",
    "\n",
    "# Annotate word onset and phonemes\n",
    "for i, word_onset in enumerate(ds.word_onsets + ds.phoneme_onsets[:, 0]):\n",
    "    h_onset = ax.axvline(word_onset, c=\"orange\", linestyle=\"--\")\n",
    "    for j, phoneme_onset in enumerate(word_onset + ds.phoneme_onsets[i]):\n",
    "        phon = ds.phonemes[ds.candidate_phonemes[i, 0, j]]\n",
    "        if phon != \"_\":\n",
    "            font_weight = \"bold\" if j == recognition_points[i] else None\n",
    "            ax.annotate(phon, xy=(phoneme_onset, annot_height), fontweight=font_weight)\n",
    "# Annotate recognition onset\n",
    "for rec_onset in ds.word_onsets + recognition_onsets:\n",
    "    h_recognition = ax.axvline(rec_onset, c=\"green\", linestyle=\"--\")\n",
    "    \n",
    "# Annotate evidence climb to recognition\n",
    "right_ax = ax.twinx()\n",
    "h_threshold = right_ax.axhline(params.threshold, c=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "for i, (length, phoneme_onsets, incremental_gt_prob) in enumerate(zip(ds.word_lengths, ds.word_onsets[:, None] + ds.phoneme_onsets, incremental_gt_probabilities)):\n",
    "    xs = phoneme_onsets[:length]\n",
    "    ys = incremental_gt_prob[:length]\n",
    "    h_evidence, = right_ax.plot(xs, ys, c=\"gray\", alpha=0.7)\n",
    "\n",
    "ax.legend([h_onset, h_recognition, h_threshold, h_evidence],\n",
    "          [\"Word onset\", \"Recognition onset\", \"Evidence threshold\", \"Evidence accumulation\"],\n",
    "          loc='center left', bbox_to_anchor=(1.025, 0.5))\n",
    "    \n",
    "ax.set_xlim((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbf630-fe21-4728-aba2-3549ff88f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = ((ds.recognition_onsets + ds.params.a - ds.epoch_window[0]).numpy() * ds.sample_rate).astype(int)\n",
    "ds.Y_epoch[np.arange(len(ds.Y_epoch)), offsets + 3][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40249c48-20a5-4b5b-8b36-61f70bf61cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.p_word[:3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71412da8-dcf9-43af-8998-dd195c6572cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.X_epoch[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b7b8c-3e52-46a3-a818-c3368151e8d8",
   "metadata": {},
   "source": [
    "## N400 replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa925b06-ed6b-4149-88e4-59258e47fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(ds.Y_epoch.shape[1]) / ds.sample_rate, ds.Y_epoch[3, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bf97a-2e65-40a2-8be2-ad28042401f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(ds.Y_epoch.numpy().squeeze())\n",
    "y_df.index.name = \"cum_token_idx\"\n",
    "y_df.columns.name = \"epoch_sample\"\n",
    "y_df = y_df.unstack().rename(\"signal\").reset_index()\n",
    "y_df[\"time\"] = y_df.epoch_sample / ds.sample_rate + ds.epoch_window[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7894b4-c7b5-4e9d-8dd6-74e75a10c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_baselines = y_df[y_df.time <= 0].groupby(\"cum_token_idx\").signal.mean()\n",
    "y_df[\"signal_baselined\"] = y_df.signal - y_df.cum_token_idx.map(epoch_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a88700-91bf-4a77-ab79-f03990427de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=y_df, x=\"time\", y=\"signal_baselined\")\n",
    "ax.axvline(0, c=\"gray\")\n",
    "ax.axhline(0, c=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7360c3-923d-4004-9724-c970afb0569b",
   "metadata": {},
   "source": [
    "### N400 replication\n",
    "\n",
    "With ground-truth recognition onset information, can we reproduce an N400 effect with ERP analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205bbf6e-ae7e-482a-87b2-2806091f2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window_to_sample(window, sample_rate, t_zero=0.):\n",
    "    left, right = window\n",
    "    \n",
    "    left = int(np.floor((left - t_zero) * sample_rate))\n",
    "    right = int(np.floor((right - t_zero) * sample_rate))\n",
    "    return (left, right)\n",
    "\n",
    "def compute_erp(dataset: rr.RRDataset,\n",
    "                baseline_window=(-0.1, 0),\n",
    "                test_window=None,\n",
    "                use_recognition_onset=True\n",
    "                ) -> pd.DataFrame:\n",
    "    if test_window is None:\n",
    "        test_window = (dataset.params.a, dataset.params.a + dataset.params.b)\n",
    "\n",
    "    baseline_left_samp, baseline_right_samp = time_window_to_sample(baseline_window, dataset.sample_rate,\n",
    "                                                                    t_zero=dataset.epoch_window[0])\n",
    "    test_left_samp, test_right_samp = time_window_to_sample(test_window, dataset.sample_rate,\n",
    "                                                            t_zero=dataset.epoch_window[0])\n",
    "    \n",
    "    if use_recognition_onset:\n",
    "        recognition_onset_samp = np.floor(dataset.recognition_onsets * sample_rate).int().numpy()\n",
    "        test_values = [dataset.Y_epoch[i, recognition_onset_samp_i + test_left_samp:recognition_onset_samp_i + test_right_samp, 0].mean()\n",
    "                       for i, recognition_onset_samp_i in enumerate(recognition_onset_samp)]\n",
    "        test_values = torch.stack(test_values)\n",
    "    else:\n",
    "        test_values = dataset.Y_epoch[:, test_left_samp:test_right_samp, 0].mean()\n",
    "    \n",
    "    baseline_values = dataset.Y_epoch[:, baseline_left_samp:baseline_right_samp, 0]\n",
    "\n",
    "    return pd.DataFrame({\"cum_token_idx\": np.arange(len(dataset.Y_epoch)),\n",
    "                         \"baseline_value\": baseline_values.mean(dim=1),\n",
    "                         \"test_value\": test_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be470a2b-e801-488a-9e5b-d6f3f050d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_df = compute_erp(ds)\n",
    "erp_df[\"surprisal\"] = ds.X_epoch[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245b446-ff58-42c7-a231-7ba349888379",
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35c490-d682-48c9-a9c5-4d7856b681b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_df.sort_values(\"surprisal\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf70580-fd43-47b7-9a8f-3c0272901f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_window = (-.1, 0)\n",
    "# test_window = (0.3, 0.5)\n",
    "# df_test = epochs.groupby([\"item\", \"token_idx\"]).apply(\n",
    "#     lambda rows: pd.Series({\"epoch_baseline\": rows[(rows.epoch_time >= baseline_window[0]) & (rows.epoch_time < baseline_window[1])].signal.mean(),\n",
    "#                             \"epoch_value\": rows[(rows.epoch_time >= test_window[0]) & (rows.epoch_time < test_window[1])].signal.mean()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3158e98-4a8b-42a9-a10b-a61907e6a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.merge(df_test, raw_dataset.X_word, left_index=True, right_index=True)\n",
    "# merged_df[\"epoch_value_baselined\"] = merged_df.epoch_value - merged_df.epoch_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950d4fe-0b4f-4c6f-8ef5-5bdc7c9b97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_df[\"epoch_value_baselined\"] = erp_df.test_value - erp_df.baseline_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68f1e3-2863-40d8-b0d9-a9dfd02d7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=erp_df, x=\"surprisal\", y=\"epoch_value_baselined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad5f35-a7e5-42fe-8910-ba28910ae2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.pearsonr(erp_df.surprisal, erp_df.epoch_value_baselined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
