from pathlib import Path
import itertools

# TODO config schema?

# Project root directory
root_dir = Path(workflow.basedir).parent

model = config["language_modeling"]["model"]


# # Glossary
#
# Task = stimulus = story. Tasks are indexed by integers and are ordered the same
# across subjects/sessions.
# TODO double-check this for all subjects+sessions
#
# # Other notes
#
# - NB that the general variable order for naming files here is
#   `task`, `subject`, `session`. This matches the Berp standard, where subject-session-level
#   data are categorized within stimulus.

# Read specified subjects/sessions/tasks for loading
SUBJECTS, SESSIONS, TASKS = config['subjects'], config['sessions'], config['tasks'].keys()


wildcard_constraints:
    subject = "\d+",
    session = "\d+",
    task = "\d+",
    story_name = "\w+"


def take_first(expr, **wildcards):
    """
    Produce inputs drawing the first element of each of the given `wildcards`.
    This is useful when using denormalized data and we don't care which of the inputs we
    use -- we just need some reference.
    """
    return expand(expr, **{wildcard: values[0] for wildcard, values in wildcards.items()})


task_to_story_name = config["tasks"]
story_name_to_task = {v: k for k, v in task_to_story_name.items()}


def f(*args, **kwargs):
    print(args)
    print(kwargs)
    sys.exit(1)

# Extract data about the presentation of a task to a subject in a given session.
# Each "task" corresponds to a stimulus (story). NB the resulting extracted presentation
# data is highly denormalized, containing redundant information about phonemes and words
# that are repeated across stories.
#
# The unique data in each run of this rule is simply the timing of the stimulus presentation
# relative to the subject-session's EEG time series.
rule extract_presentation_data:
    input:
        lambda wildcards:
            expand("raw-data/sub-{{subject}}/ses-{{session}}/meg/sub-{{subject}}_ses-{{session}}_task-{task}_meg.con",
                   task=story_name_to_task[wildcards.story_name],
                   allow_missing=True)
    output:
        output_dir = directory("data/presentation/{story_name}/{subject}/{session}"),
        sounds = "data/presentation/{story_name}/{subject}/{session}/sound.csv",
        words = "data/presentation/{story_name}/{subject}/{session}/word.csv",
        phonemes = "data/presentation/{story_name}/{subject}/{session}/phoneme.csv"

    # TODO after this step, there should be a check/assertion that the time series
    # are uniform between subjects after baselining
    # At the same time, save the offsets relevant for aligning things later on.
    shell:
        """
        papermill scripts/meg-masc/extract_presentation_data.ipynb /dev/null \
            -p story_name {wildcards.story_name} \
            -p meg_path {input} \
            -p output_dir {output.output_dir}
        """


rule tokenized:
    input: "data/raw-text/{story_name}.txt"
    output: "data/tokenized/{model}/{story_name}.txt"
    shell:
        """
        papermill scripts/meg-masc/tokenize.ipynb /dev/null \
            -p model {wildcards.model} \
            -p input_path {input} \
            -p output_path {output}
        """


# Match up force-aligned corpus with raw text corpus on a token-to-token level.
# This will allow us to use token-level features computed on the latter corpus
# together with the timing data from the former.
rule align_with_raw_text:
    input:
        presentation_words = lambda _:
            take_first("data/presentation/{{story_name}}/{subject}/{session}/word.csv",
                          subject=SUBJECTS, session=SESSIONS),
        presentation_phonemes = lambda _:
            take_first("data/presentation/{{story_name}}/{subject}/{session}/phoneme.csv",
                          subject=SUBJECTS, session=SESSIONS),
        tokenized = "data/tokenized/{model}/{story_name}.txt"
    output:
        aligned_words = "data/aligned/{model}/{story_name}/word.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}/phoneme.csv"
    shell:
        """
        python scripts/meg-masc/align_with_raw_text.py \
            -m {wildcards.model} \
            -o data/aligned/{wildcards.model} \
            {input.tokenized} {input.presentation_words} {input.presentation_phonemes}
        """


# Run a language model on the resulting aligned text inputs and generate a
# NaturalLanguageStimulus, representing word- and phoneme-level prior predictive
# distributions.
rule run_language_modeling:
    input:
        tokenized = "data/tokenized/{model}/{story_name}.txt",
        aligned_words = "data/aligned/{model}/{story_name}.word.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}.phoneme.csv"
    output:
        stimulus = "data/stimulus/{model}/{story_name}.pkl"
    shell:
        """
        python scripts/meg-masc/run_language_modeling.py \
            -m {wildcards.model} \
            -n {{config['language_modeling']['n_candidates']}} \
            --vocab_path {{config['language_modeling']['vocab_path']}} \
            -o {output.stimulus} \
            {input.tokenized} {input.aligned_words} {input.aligned_phonemes}
        """


# TODO use computed offsets before to align stimulus+EEG data between subject-sessions


# Produce a BerpDataset from the aligned corpora for a single subject/session.
rule produce_dataset:
    params:
        task = lambda wildcards: story_name_to_task[wildcards.story_name]
    input:
        presentation_words = "data/presentation/{story_name}/{subject}/{session}.word.csv",
        presentation_phonemes = "data/presentation/{story_name}/{subject}/{session}.phoneme.csv",

        aligned_words = "data/aligned/{model}/{story_name}/word.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}/phoneme.csv",

        stimulus = "data/stimulus/{model}/{story_name}.pkl",

        bids = lambda wildcards:
            expand("raw-data/sub-{{subject}}/ses-{{session}}/meg/sub-{{subject}}_ses-{{session}}_task-{task}_meg.con",
                   task=story_name_to_task[wildcards.story_name])
    output:
        dataset = "data/dataset/{model}/{story_name}/{subject}/{session}.pkl"


# Average EEG response time series for colection of aligned subject-session datasets.
rule produce_average_dataset:
    input:
        datasets = expand("data/dataset/{model}/{story_name}/{subject}/{session}.pkl",
                          subject=SUBJECTS, session=SESSIONS, allow_missing=True)
    output:
        dataset = "data/dataset/{model}/{story_name}/average.pkl"
    script: "{root_dir}/scripts/meg-masc/average_datasets.py"