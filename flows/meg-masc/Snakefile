from pathlib import Path
import itertools

configfile: "config.yaml"
base_dir = Path(__file__).parent

model = config["language_modeling"]["model"]


# # Glossary
#
# Task = stimulus = story. Tasks are indexed by integers and are ordered the same
# across subjects/sessions.
# TODO double-check this for all subjects+sessions
#
# # Other notes
#
# - NB that the general variable order for naming files here is
#   `task`, `subject`, `session`. This matches the Berp standard, where subject-session-level
#   data are categorized within stimulus.

# Read specified subjects/sessions/tasks for loading
SUBJECTS, SESSIONS, TASKS = config['subjects'], config['sessions'], config['tasks']


wildcard_constraints:
    subject = "\d+",
    session = "\d+",
    task = "\d+",
    story_name = "\w+"


def take_first(expr, **wildcards):
    """
    Produce inputs drawing the first element of each of the given `wildcards`.
    This is useful when using denormalized data and we don't care which of the inputs we
    use -- we just need some reference.
    """
    return expand(expr, **{wildcard: values[0] for wildcard, values in wildcards.items()})


task_to_story_name = {
    0: "lw1",
    1: "cable_spool_fort",
    2: "easy_money",
    3: "the_black_willow",
}
story_name_to_task = {v: k for k, v in task_to_story_name.items()}


# Extract data about the presentation of a task to a subject in a given session.
# Each "task" corresponds to a stimulus (story). NB the resulting extracted presentation
# data is highly denormalized, containing redundant information about phonemes and words
# that are repeated across stories.
#
# The unique data in each run of this rule is simply the timing of the stimulus presentation
# relative to the subject-session's EEG time series.
rule extract_presentation_data:
    input:
        lambda wildcards:
            expand("raw-data/sub-{{subject}}/ses-{{session}}/meg/sub-{{subject}}_ses-{{session}}_task-{task}_meg.con",
                   task=story_name_to_task[wildcards.story_name],
                   allow_missing=True)
    output:
        words = "data/presentation/{story_name}.{subject}.{session}.words.csv",
        phonemes = "data/presentation/{story_name}.{subject}.{session}.phonemes.csv"

    # TODO after this step, there should be a check/assertion that the time series
    # are uniform between subjects after baselining
    # At the same time, save the offsets relevant for aligning things later on.
    script: "{base_dir}/scripts/meg-masc/extract_presentation_data.py"


rule tokenized:
    input: "raw-data/stimuli/text/{story_name}.txt"
    output: "data/tokenized/{model}/{story_name}.txt"
    script: "{base_dir}/scripts/meg-masc/tokenize.py"


# Match up force-aligned corpus with raw text corpus on a token-to-token level.
# This will allow us to use token-level features computed on the latter corpus
# together with the timing data from the former.
rule align_with_raw_text:
    input:
        presentation_words = lambda _:
            take_first("data/presentation/{{story_name}}.{subject}.{session}.words.csv",
                          subject=SUBJECTS, session=SESSIONS),
        presentation_phonemes = lambda _:
            take_first("data/presentation/{{story_name}}.{subject}.{session}.phonemes.csv",
                          subject=SUBJECTS, session=SESSIONS),
        tokenized = "data/tokenized/{model}/{story_name}.txt"
    output:
        aligned_words = "data/aligned/{model}/{story_name}.words.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}.phonemes.csv"
    shell:
        """
        python {base_dir}/scripts/meg-masc/align_with_raw_text.py \
            -m {model} \
            -o data/aligned/{model} \
            {input.tokenized} {input.presentation_words} {input.presentation_phonemes}
        """


# Run a language model on the resulting aligned text inputs and generate a
# NaturalLanguageStimulus, representing word- and phoneme-level prior predictive
# distributions.
rule run_language_modeling:
    input:
        tokenized = "data/tokenized/{model}/{story_name}.txt",
        aligned_words = "data/aligned/{model}/{story_name}.words.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}.phonemes.csv"
    output:
        stimulus = "data/stimulus/{model}/{story_name}.pkl"
    shell:
        """
        python {base_dir}/scripts/meg-masc/run_language_modeling.py \
            -m {model} \
            -n {{config['language_modeling']['n_candidates']}} \
            --vocab_path {{config['language_modeling']['vocab_path']}} \
            -o {output.stimulus} \
            {input.tokenized} {input.aligned_words} {input.aligned_phonemes}
        """


# TODO use computed offsets before to align stimulus+EEG data between subject-sessions


# Produce a BerpDataset from the aligned corpora for a single subject/session.
rule produce_dataset:
    params:
        task = lambda wildcards: story_name_to_task[wildcards.story_name]
    input:
        presentation_words = "data/presentation/{story_name}.{subject}.{session}.words.csv",
        presentation_phonemes = "data/presentation/{story_name}.{subject}.{session}.phonemes.csv",

        aligned_words = "data/aligned/{model}/{story_name}.words.csv",
        aligned_phonemes = "data/aligned/{model}/{story_name}.phonemes.csv",

        stimulus = "data/stimulus/{model}/{story_name}.pkl",

        bids = lambda wildcards:
            expand("raw-data/sub-{{subject}}/ses-{{session}}/meg/sub-{{subject}}_ses-{{session}}_task-{task}_meg.con",
                   task=story_name_to_task[wildcards.story_name])
    output:
        dataset = "data/dataset/{model}/{story_name}.{subject}.{session}.pkl"


# Average EEG response time series for colection of aligned subject-session datasets.
rule produce_average_dataset:
    input:
        datasets = expand("data/dataset/{model}/{story_name}.{subject}.{session}.pkl",
                          subject=SUBJECTS, session=SESSIONS, allow_missing=True)
    output:
        dataset = "data/dataset/{model}/{story_name}.average.pkl"
    script: "{base_dir}/scripts/meg-masc/average_datasets.py"