{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0493fda1-ece2-487f-b3db-9e8f8eab1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df13cd94-973a-42aa-8f34-66e94d7d5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from berp.languages import english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a02519-c4f3-4020-b4b7-0234d6413ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-08 16:11:45--  http://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b [following]\n",
      "--2023-05-08 16:11:45--  https://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3865710 (3.7M) [text/plain]\n",
      "Saving to: ‘cmudict-0.7b’\n",
      "\n",
      "100%[======================================>] 3,865,710   --.-K/s   in 0.1s    \n",
      "\n",
      "2023-05-08 16:11:46 (36.4 MB/s) - ‘cmudict-0.7b’ saved [3865710/3865710]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://raw.githubusercontent.com/Alexir/CMUdict/master/cmudict-0.7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee6021-0d77-4b69-abbd-d060b7f45594",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Syllabifier\n",
    "\n",
    "From https://github.com/georgiee/lip-sync-lpc/blob/master/sources/p2tk/python/syllabify/syllabifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e063caa-2e2c-4dbd-8cce-08d80bf8dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPA stress annotations\n",
    "ipa_stress_primary = \"ˈ\"\n",
    "ipa_stress_secondary = \"ˌ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4971e141-39c5-46c7-8cfc-c5208d434503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the P2TK automated syllabifier. Given a string of phonemes,\n",
    "# it automatically divides the phonemes into syllables.\n",
    "#\n",
    "# By Joshua Tauberer, based on code originally written by Charles Yang.\n",
    "#\n",
    "# The syllabifier requires a language configuration which specifies\n",
    "# the set of phonemes which are consonants and vowels (syllable nuclei),\n",
    "# as well as the set of permissible onsets.\n",
    "#\n",
    "# Then call syllabify with a language configuration object and a word\n",
    "# represented as a string (or list) of phonemes.\n",
    "#\n",
    "# Returned is a data structure representing the syllabification.\n",
    "# What you get is a list of syllables. Each syllable is a tuple\n",
    "# of (stress, onset, nucleus, coda). stress is None or an integer stress\n",
    "# level attached to the nucleus phoneme on input. onset, nucleus,\n",
    "# and coda are lists of phonemes.\n",
    "#\n",
    "# Example:\n",
    "#\n",
    "# import syllabifier\n",
    "# language = syllabifier.English # or: syllabifier.loadLanguage(\"english.cfg\")\n",
    "# syllables = syllabifier.syllabify(language, \"AO2 R G AH0 N AH0 Z EY1 SH AH0 N Z\")\n",
    "#\n",
    "# The syllables variable then holds the following:\n",
    "# [ (2, [],     ['AO'], ['R']),\n",
    "#   (0, ['G'],  ['AH'], []),\n",
    "#   (0, ['N'],  ['AH'], []),\n",
    "#   (1, ['Z'],  ['EY'], []),\n",
    "#   (0, ['SH'], ['AH'], ['N', 'Z'])]\n",
    "#\n",
    "# You could process that result with this type of loop:\n",
    "#\n",
    "# for stress, onset, nucleus, coda in syllables :\n",
    "#   print \" \".join(onset), \" \".join(nucleus), \" \".join(coda)\n",
    "#\n",
    "# You can also pass the result to stringify to get a nice printable\n",
    "# representation of the syllables, with periods separating syllables:\n",
    "#\n",
    "# print syllabify.stringify(syllables)\n",
    "#\n",
    "#########################################################################\n",
    "\n",
    "English = {\n",
    "\t'consonants': ['B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', \n",
    "\t'NG', 'P', 'R', 'S', 'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH'],\n",
    "\t'vowels': [ 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW'],\n",
    "\t'onsets': ['P', 'T', 'K', 'B', 'D', 'G', 'F', 'V', 'TH', 'DH', 'S', 'Z', 'SH', 'CH', 'JH', 'M',\n",
    "\t'N', 'R', 'L', 'HH', 'W', 'Y', 'P R', 'T R', 'K R', 'B R', 'D R', 'G R', 'F R',\n",
    "\t'TH R', 'SH R', 'P L', 'K L', 'B L', 'G L', 'F L', 'S L', 'T W', 'K W', 'D W', \n",
    "\t'S W', 'S P', 'S T', 'S K', 'S F', 'S M', 'S N', 'G W', 'SH W', 'S P R', 'S P L',\n",
    "\t'S T R', 'S K R', 'S K W', 'S K L', 'TH W', 'ZH', 'P Y', 'K Y', 'B Y', 'F Y', \n",
    "\t'HH Y', 'V Y', 'TH Y', 'M Y', 'S P Y', 'S K Y', 'G Y', 'HH W', '']\n",
    "\t}\n",
    "\n",
    "def loadLanguage(filename) :\n",
    "\t'''This function loads up a language configuration file and returns\n",
    "\tthe configuration to be passed to the syllabify function.'''\n",
    "\n",
    "\tL = { \"consonants\" : [], \"vowels\" : [], \"onsets\" : [] }\n",
    "\t\n",
    "\tf = open(filename, \"r\")\n",
    "\tsection = None\n",
    "\tfor line in f :\n",
    "\t\tline = line.strip()\n",
    "\t\tif line in (\"[consonants]\", \"[vowels]\", \"[onsets]\") :\n",
    "\t\t\tsection = line[1:-1]\n",
    "\t\telif section == None :\n",
    "\t\t\traise ValueError(\"File must start with a section header such as [consonants].\")\n",
    "\t\telif not section in L :\n",
    "\t\t\traise ValueError(\"Invalid section: \" + section)\n",
    "\t\telse :\n",
    "\t\t\tL[section].append(line)\n",
    "\t\t\t\n",
    "\tfor section in \"consonants\", \"vowels\", \"onsets\" :\n",
    "\t\tif len(L[section]) == 0 :\n",
    "\t\t\traise ValueError(\"File does not contain any consonants, vowels, or onsets.\")\n",
    "\t\t\t\n",
    "\treturn L\n",
    "\n",
    "def syllabify(language, word) :\n",
    "\t'''Syllabifies the word, given a language configuration loaded with loadLanguage.\n",
    "\t   word is either a string of phonemes from the CMU pronouncing dictionary set\n",
    "\t   (with optional stress numbers after vowels), or a Python list of phonemes,\n",
    "\t   e.g. \"B AE1 T\" or [\"B\", \"AE1\", \"T\"]'''\n",
    "\t   \n",
    "\tif type(word) == str :\n",
    "\t\tword = word.split()\n",
    "\t\t\n",
    "\tsyllables = [] # This is the returned data structure.\n",
    "\n",
    "\tinternuclei = [] # This maintains a list of phonemes between nuclei.\n",
    "\t\n",
    "\tfor phoneme in word :\n",
    "\t\n",
    "\t\tphoneme = phoneme.strip()\n",
    "\t\tif phoneme == \"\" :\n",
    "\t\t\tcontinue\n",
    "\t\tstress = None\n",
    "\t\tif phoneme[-1].isdigit() :\n",
    "\t\t\tstress = int(phoneme[-1])\n",
    "\t\t\tphoneme = phoneme[0:-1]\n",
    "\t\t\n",
    "\t\tif phoneme in language[\"vowels\"] :\n",
    "\t\t\t# Split the consonants seen since the last nucleus into coda and onset.\n",
    "\t\t\t\n",
    "\t\t\tcoda = None\n",
    "\t\t\tonset = None\n",
    "\t\t\t\n",
    "\t\t\t# If there is a period in the input, split there.\n",
    "\t\t\tif \".\" in internuclei :\n",
    "\t\t\t\tperiod = internuclei.index(\".\")\n",
    "\t\t\t\tcoda = internuclei[:period]\n",
    "\t\t\t\tonset = internuclei[period+1:]\n",
    "\t\t\t\n",
    "\t\t\telse :\n",
    "\t\t\t\t# Make the largest onset we can. The 'split' variable marks the break point.\n",
    "\t\t\t\tfor split in range(0, len(internuclei)+1) :\n",
    "\t\t\t\t\tcoda = internuclei[:split]\n",
    "\t\t\t\t\tonset = internuclei[split:]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# If we are looking at a valid onset, or if we're at the start of the word\n",
    "\t\t\t\t\t# (in which case an invalid onset is better than a coda that doesn't follow\n",
    "\t\t\t\t\t# a nucleus), or if we've gone through all of the onsets and we didn't find\n",
    "\t\t\t\t\t# any that are valid, then split the nonvowels we've seen at this location.\n",
    "\t\t\t\t\tif \" \".join(onset) in language[\"onsets\"] \\\n",
    "\t\t\t\t\t   or len(syllables) == 0 \\\n",
    "\t\t\t\t\t   or len(onset) == 0 :\n",
    "\t\t\t\t\t   break\n",
    "\t\t\t   \n",
    "\t\t\t# Tack the coda onto the coda of the last syllable. Can't do it if this\n",
    "\t\t\t# is the first syllable.\n",
    "\t\t\tif len(syllables) > 0 :\n",
    "\t\t\t\tsyllables[-1][3].extend(coda)\n",
    "\t\t\t\n",
    "\t\t\t# Make a new syllable out of the onset and nucleus.\n",
    "\t\t\tsyllables.append( (stress, onset, [phoneme], []) )\n",
    "\t\t\t\t\n",
    "\t\t\t# At this point we've processed the internuclei list.\n",
    "\t\t\tinternuclei = []\n",
    "\n",
    "\t\telif not phoneme in language[\"consonants\"] and phoneme != \".\" :\n",
    "\t\t\traise ValueError(\"Invalid phoneme: \" + phoneme)\n",
    "\t\t\t\n",
    "\t\telse : # a consonant\n",
    "\t\t\tinternuclei.append(phoneme)\n",
    "\t\n",
    "\t# Done looping through phonemes. We may have consonants left at the end.\n",
    "\t# We may have even not found a nucleus.\n",
    "\tif len(internuclei) > 0 :\n",
    "\t\tif len(syllables) == 0 :\n",
    "\t\t\tsyllables.append( (None, internuclei, [], []) )\n",
    "\t\telse :\n",
    "\t\t\tsyllables[-1][3].extend(internuclei)\n",
    "\n",
    "\treturn syllables\n",
    "\n",
    "def stringify(syllables) :\n",
    "\t'''This function takes a syllabification returned by syllabify and\n",
    "\t   turns it into a string, with phonemes spearated by spaces and\n",
    "\t   syllables spearated by periods.'''\n",
    "\tret = []\n",
    "\tfor syl in syllables :\n",
    "\t\tstress, onset, nucleus, coda = syl\n",
    "\t\tif stress == 1:\n",
    "\t\t\tret.append(ipa_stress_primary)\n",
    "\t\telif stress == 2:\n",
    "\t\t\tret.append(ipa_stress_secondary)\n",
    "\t\telse:\n",
    "\t\t\tret.append(\".\")\n",
    "\t\tret.append(\" \".join(onset + nucleus + coda))\n",
    "\treturn \" \".join(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fcea23-2dd3-4752-a5de-5f7bb80ba4b8",
   "metadata": {},
   "source": [
    "## Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f46fe91-89dc-443b-9a29-4822604611c2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_path = \"cmudict-0.7b\"\n",
    "output_path = \"cmudict_ipa.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a210566b-d048-4682-b9aa-5fc30956a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "brackets_re = re.compile(r\"\\(\\d+\\)\")\n",
    "stress_re = re.compile(r\"[012]\")\n",
    "comments_re = re.compile(r\"\\s*#.+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8742e2ce-b69a-4c26-adbd-9941a06974f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22a03716-bb02-42a0-bdf4-6c42379c6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, pron in english.cmudict_overrides.items():\n",
    "    mapping[word].append(pron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08470369-1542-46f0-9a36-c8762cff2eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf5bd58d473408291b2425f8b8b2b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(input_path, encoding=\"latin-1\") as f:\n",
    "    i = 0\n",
    "    for line in tqdm(f.readlines()):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\";;;\"):\n",
    "            continue\n",
    "\n",
    "        word, arpa = line.split(\" \", 1)\n",
    "        word = brackets_re.sub(\"\", word)\n",
    "        arpa_with_stress = stringify(syllabify(English, arpa)).strip().split(\" \")\n",
    "        \n",
    "        result = []\n",
    "        for part in arpa_with_stress:\n",
    "            # Let syllable annotations pass through\n",
    "            if part in [\".\", ipa_stress_primary, ipa_stress_secondary]:\n",
    "                ipa = part\n",
    "            else:\n",
    "                ipa = english.cmu_ipa_mapping[part]\n",
    "            result.append(ipa)\n",
    "            \n",
    "        mapping[word].append(\" \".join(result))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "911974d8-57d3-42a5-954e-0ff1367c02a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation_idx</th>\n",
       "      <th>pronunciation_syllable</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ w ʌ z</td>\n",
       "      <td>w ʌ z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was</td>\n",
       "      <td>1</td>\n",
       "      <td>ˈ w ɑ z</td>\n",
       "      <td>w ɑ z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>2</td>\n",
       "      <td>. w ɑ z</td>\n",
       "      <td>w ɑ z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ w ɪ n d</td>\n",
       "      <td>w ɪ n d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "      <td>ˈ w aɪ n d</td>\n",
       "      <td>w aɪ n d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134431</th>\n",
       "      <td>{brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ b ɹ ɛɪ s</td>\n",
       "      <td>b ɹ ɛɪ s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134432</th>\n",
       "      <td>{left-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ l ɛ f t ˈ b ɹ ɛɪ s</td>\n",
       "      <td>l ɛ f t b ɹ ɛɪ s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134433</th>\n",
       "      <td>{open-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ oʊ . p ɛ n ˈ b ɹ ɛɪ s</td>\n",
       "      <td>oʊ p ɛ n b ɹ ɛɪ s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134434</th>\n",
       "      <td>}close-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ k l oʊ z ˈ b ɹ ɛɪ s</td>\n",
       "      <td>k l oʊ z b ɹ ɛɪ s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134435</th>\n",
       "      <td>}right-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ ɹ aɪ t ˈ b ɹ ɛɪ s</td>\n",
       "      <td>ɹ aɪ t b ɹ ɛɪ s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134436 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  pronunciation_idx   pronunciation_syllable  \\\n",
       "0                was                  0                  ˈ w ʌ z   \n",
       "1                was                  1                  ˈ w ɑ z   \n",
       "2                was                  2                  . w ɑ z   \n",
       "3               wind                  0                ˈ w ɪ n d   \n",
       "4               wind                  1               ˈ w aɪ n d   \n",
       "...              ...                ...                      ...   \n",
       "134431        {brace                  0               ˈ b ɹ ɛɪ s   \n",
       "134432   {left-brace                  0     ˈ l ɛ f t ˈ b ɹ ɛɪ s   \n",
       "134433   {open-brace                  0  ˈ oʊ . p ɛ n ˈ b ɹ ɛɪ s   \n",
       "134434  }close-brace                  0    ˈ k l oʊ z ˈ b ɹ ɛɪ s   \n",
       "134435  }right-brace                  0      ˈ ɹ aɪ t ˈ b ɹ ɛɪ s   \n",
       "\n",
       "            pronunciation  \n",
       "0                   w ʌ z  \n",
       "1                   w ɑ z  \n",
       "2                   w ɑ z  \n",
       "3                 w ɪ n d  \n",
       "4                w aɪ n d  \n",
       "...                   ...  \n",
       "134431           b ɹ ɛɪ s  \n",
       "134432   l ɛ f t b ɹ ɛɪ s  \n",
       "134433  oʊ p ɛ n b ɹ ɛɪ s  \n",
       "134434  k l oʊ z b ɹ ɛɪ s  \n",
       "134435    ɹ aɪ t b ɹ ɛɪ s  \n",
       "\n",
       "[134436 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataframe\n",
    "rows = [(word.lower(), i, pron) for word, prons in mapping.items()\n",
    "        for i, pron in enumerate(prons)]\n",
    "df = pd.DataFrame(rows, columns=[\"word\", \"pronunciation_idx\", \"pronunciation_syllable\"])\n",
    "df[\"pronunciation\"] = df.pronunciation_syllable.str.replace(f\"[.{ipa_stress_primary}{ipa_stress_secondary}]\\s+\", \"\", regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e045bf48-88b4-427f-8a9a-5e509573a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
