{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b0bb86-ac22-42dc-857d-05c0543fb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "from typing import List, Tuple, Optional\n",
    "from typing_extensions import TypeAlias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(str(Path(\".\").resolve().parent.parent))\n",
    "from berp.datasets import Phoneme\n",
    "from berp.datasets import NaturalLanguageStimulusProcessor\n",
    "from berp.languages import english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8821262c-eaee-4bc0-af30-2e51dc82e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WordForm: TypeAlias = Tuple[Phoneme, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4fb149-26b5-4d16-989e-4989f35cc353",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tokenized_path = \"oms.txt\"\n",
    "aligned_words_path = \"word.csv\"\n",
    "aligned_phonemes_path = \"phoneme.csv\"\n",
    "story_name = \"old-man-and-the-sea\"\n",
    "\n",
    "cmu_ipa_dict_path = \"cmudict_ipa.csv\"\n",
    "vocab_path = \"../../workflow/heilbron2022/data/frequency/subtlexus2.csv\"\n",
    "\n",
    "output_dir = \"old-man-and-the-sea\"\n",
    "\n",
    "model = \"distilgpt2\"\n",
    "n_candidates = 100#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399b9d36-6404-4c88-855a-12bc43760f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(output_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bd384-11b6-4224-97fd-6b195e7afe3f",
   "metadata": {},
   "source": [
    "## Prepare tokenized data and aligned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ebaaa8-6f90-46c4-af17-2a38a5496f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Path(tokenized_path).read_text().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507510e8-913b-4c86-835a-04e13b147f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_csv(aligned_words_path, index_col=[0, 1])\n",
    "phonemes_df = pd.read_csv(aligned_phonemes_path, index_col=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815b8f20-fa3f-4222-9d38-c7e8f4584b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ʌ     3376\n",
       "t     2378\n",
       "n     2374\n",
       "d     1957\n",
       "ɪ     1850\n",
       "ð     1505\n",
       "l     1388\n",
       "i     1334\n",
       "s     1270\n",
       "ɹ     1142\n",
       "h     1033\n",
       "m      962\n",
       "ɛ      950\n",
       "z      936\n",
       "k      932\n",
       "w      930\n",
       "æ      814\n",
       "ɚ      763\n",
       "b      722\n",
       "f      699\n",
       "aɪ     618\n",
       "oʊ     610\n",
       "ɛɪ     536\n",
       "ɔ      517\n",
       "u      514\n",
       "v      499\n",
       "ɑ      478\n",
       "p      442\n",
       "ŋ      387\n",
       "g      295\n",
       "ʃ      284\n",
       "aʊ     263\n",
       "θ      258\n",
       "ʊ      230\n",
       "j      172\n",
       "ɔɪ     117\n",
       "tʃ     116\n",
       "dʒ      79\n",
       "ʒ        5\n",
       "Name: phoneme, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes_df.phoneme.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b61d26-325b-4cd6-85cc-2c9e266d6fbf",
   "metadata": {},
   "source": [
    "## Prepare frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb29b52-c74f-4991-bd46-c63c3878ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_df = pd.read_csv(vocab_path, sep=\"\\t\")\n",
    "\n",
    "frequency_df[\"Word\"] = frequency_df.Word.str.lower()\n",
    "assert frequency_df.Word.value_counts().max() == 1\n",
    "\n",
    "frequency_df[\"log_freq\"] = -np.log2(frequency_df.FREQcount / frequency_df.FREQcount.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7afcba48-1626-48bb-8ec5-a957912e57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df[\"word_lower\"] = words_df.word.str.lower()\n",
    "old_size = len(words_df)\n",
    "words_df = pd.merge(words_df.reset_index(), frequency_df[[\"Word\", \"log_freq\"]], left_on=\"word_lower\", right_on=\"Word\",\n",
    "                    how=\"left\")\n",
    "assert len(words_df) == old_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a47c54-ff00-43e2-be6a-7a6f8646cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 (0.021%) words missing frequency values.\n",
      "Replacing with 2-percentile log-frequency: 25.56731019333269\n"
     ]
    }
   ],
   "source": [
    "# Put words with missing frequency in the lowest 2 percentile.\n",
    "missing_freq = words_df.log_freq.isna()\n",
    "print(f\"{missing_freq.sum()} ({int(missing_freq.mean() * 1000) / 1000}%) words missing frequency values.\")\n",
    "oov_freq = pd.qcut(words_df.log_freq, 50, retbins=True, duplicates=\"drop\")[1][-1]\n",
    "print(f\"Replacing with 2-percentile log-frequency: {oov_freq}\")\n",
    "words_df.loc[missing_freq, \"log_freq\"] = oov_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea24e5d-3b52-4167-8349-c9ca34900811",
   "metadata": {},
   "source": [
    "## Prepare phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0e457f-a8cf-413c-a94d-8896c9773e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation_idx</th>\n",
       "      <th>pronunciation_syllable</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>log_freq</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ w ʌ z</td>\n",
       "      <td>w ʌ z</td>\n",
       "      <td>7.429644</td>\n",
       "      <td>5.800353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was</td>\n",
       "      <td>1</td>\n",
       "      <td>ˈ w ɑ z</td>\n",
       "      <td>w ɑ z</td>\n",
       "      <td>7.429644</td>\n",
       "      <td>5.800353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>2</td>\n",
       "      <td>. w ɑ z</td>\n",
       "      <td>w ɑ z</td>\n",
       "      <td>7.429644</td>\n",
       "      <td>5.800353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wind</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ w ɪ n d</td>\n",
       "      <td>w ɪ n d</td>\n",
       "      <td>14.003161</td>\n",
       "      <td>6.090158e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "      <td>ˈ w aɪ n d</td>\n",
       "      <td>w aɪ n d</td>\n",
       "      <td>14.003161</td>\n",
       "      <td>6.090158e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134431</th>\n",
       "      <td>{brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ b ɹ ɛɪ s</td>\n",
       "      <td>b ɹ ɛɪ s</td>\n",
       "      <td>25.567310</td>\n",
       "      <td>2.011281e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134432</th>\n",
       "      <td>{left-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ l ɛ f t ˈ b ɹ ɛɪ s</td>\n",
       "      <td>l ɛ f t b ɹ ɛɪ s</td>\n",
       "      <td>25.567310</td>\n",
       "      <td>2.011281e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134433</th>\n",
       "      <td>{open-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ oʊ . p ɛ n ˈ b ɹ ɛɪ s</td>\n",
       "      <td>oʊ p ɛ n b ɹ ɛɪ s</td>\n",
       "      <td>25.567310</td>\n",
       "      <td>2.011281e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134434</th>\n",
       "      <td>}close-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ k l oʊ z ˈ b ɹ ɛɪ s</td>\n",
       "      <td>k l oʊ z b ɹ ɛɪ s</td>\n",
       "      <td>25.567310</td>\n",
       "      <td>2.011281e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134435</th>\n",
       "      <td>}right-brace</td>\n",
       "      <td>0</td>\n",
       "      <td>ˈ ɹ aɪ t ˈ b ɹ ɛɪ s</td>\n",
       "      <td>ɹ aɪ t b ɹ ɛɪ s</td>\n",
       "      <td>25.567310</td>\n",
       "      <td>2.011281e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134436 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  pronunciation_idx   pronunciation_syllable  \\\n",
       "0                was                  0                  ˈ w ʌ z   \n",
       "1                was                  1                  ˈ w ɑ z   \n",
       "2                was                  2                  . w ɑ z   \n",
       "3               wind                  0                ˈ w ɪ n d   \n",
       "4               wind                  1               ˈ w aɪ n d   \n",
       "...              ...                ...                      ...   \n",
       "134431        {brace                  0               ˈ b ɹ ɛɪ s   \n",
       "134432   {left-brace                  0     ˈ l ɛ f t ˈ b ɹ ɛɪ s   \n",
       "134433   {open-brace                  0  ˈ oʊ . p ɛ n ˈ b ɹ ɛɪ s   \n",
       "134434  }close-brace                  0    ˈ k l oʊ z ˈ b ɹ ɛɪ s   \n",
       "134435  }right-brace                  0      ˈ ɹ aɪ t ˈ b ɹ ɛɪ s   \n",
       "\n",
       "            pronunciation   log_freq          freq  \n",
       "0                   w ʌ z   7.429644  5.800353e-03  \n",
       "1                   w ɑ z   7.429644  5.800353e-03  \n",
       "2                   w ɑ z   7.429644  5.800353e-03  \n",
       "3                 w ɪ n d  14.003161  6.090158e-05  \n",
       "4                w aɪ n d  14.003161  6.090158e-05  \n",
       "...                   ...        ...           ...  \n",
       "134431           b ɹ ɛɪ s  25.567310  2.011281e-08  \n",
       "134432   l ɛ f t b ɹ ɛɪ s  25.567310  2.011281e-08  \n",
       "134433  oʊ p ɛ n b ɹ ɛɪ s  25.567310  2.011281e-08  \n",
       "134434  k l oʊ z b ɹ ɛɪ s  25.567310  2.011281e-08  \n",
       "134435    ɹ aɪ t b ɹ ɛɪ s  25.567310  2.011281e-08  \n",
       "\n",
       "[134436 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load IPA dictionary and merge in processed frequency information\n",
    "phonemizer_df = pd.read_csv(cmu_ipa_dict_path)\n",
    "phonemizer_df = pd.merge(phonemizer_df, frequency_df[[\"Word\", \"log_freq\"]], how=\"left\",\n",
    "                         left_on=\"word\", right_on=\"Word\").drop(columns=[\"Word\"])\n",
    "phonemizer_df[\"log_freq\"] = phonemizer_df.log_freq.fillna(oov_freq)\n",
    "phonemizer_df[\"freq\"] = np.power(2, -phonemizer_df.log_freq)\n",
    "phonemizer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8666ab26-0f12-43fd-81fd-2c3bdb29f5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56206b917b804fb0aba77203631f3fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phonemizer = english.Phonemizer(phonemizer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d5044d6-46f5-4ca4-b930-285135ef70d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aɪ',\n",
       " 'aʊ',\n",
       " 'b',\n",
       " 'd',\n",
       " 'dʒ',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'oʊ',\n",
       " 'p',\n",
       " 's',\n",
       " 't',\n",
       " 'tʃ',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'z',\n",
       " 'æ',\n",
       " 'ð',\n",
       " 'ŋ',\n",
       " 'ɑ',\n",
       " 'ɔ',\n",
       " 'ɔɪ',\n",
       " 'ɚ',\n",
       " 'ɛ',\n",
       " 'ɛɪ',\n",
       " 'ɪ',\n",
       " 'ɹ',\n",
       " 'ʃ',\n",
       " 'ʊ',\n",
       " 'ʌ',\n",
       " 'ʒ',\n",
       " 'θ'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ipa_chars = set(itertools.chain.from_iterable(phonemizer.mapping.values()))\n",
    "dict_ipa_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15465029-6917-4b3e-aa3d-87b559a885b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dict_ipa_chars == set(phonemes_df.phoneme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ad984-5e21-4279-bdf1-157b81cfbece",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check phonemization agreement\n",
    "\n",
    "For words with Heilbron phoneme annotations and a matching CMU annotation, check whether they agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41900a24-c3ab-4f75-ba3a-e69557594d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49c019505994a8c8df9bb2ff7600073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "misses = Counter()\n",
    "mismatches = defaultdict(list)\n",
    "matches = 0\n",
    "for _, word_data in tqdm(phonemes_df.groupby([\"run\", \"word_idx\"])):\n",
    "    word = word_data.word.iloc[0].lower()\n",
    "    heilbron_pron = word_data.phoneme.str.cat(sep=\" \")\n",
    "    \n",
    "    if word not in phonemizer.mapping:\n",
    "        misses[word] += 1\n",
    "    pron = \" \".join(phonemizer(word))\n",
    "\n",
    "    if heilbron_pron == pron:\n",
    "        matches += 1\n",
    "    else:\n",
    "        mismatches[word].append(heilbron_pron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1d7682-031d-4f27-aa29-0cab502bbccb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 231),\n",
       " ('and', 165),\n",
       " ('him', 57),\n",
       " ('them', 52),\n",
       " ('when', 42),\n",
       " ('can', 34),\n",
       " ('will', 29),\n",
       " ('into', 25),\n",
       " ('or', 22),\n",
       " ('then', 19),\n",
       " ('from', 16),\n",
       " ('for', 16),\n",
       " ('are', 15),\n",
       " ('get', 13),\n",
       " ('to', 10),\n",
       " ('has', 10),\n",
       " ('just', 9),\n",
       " ('they', 8),\n",
       " ('your', 8),\n",
       " ('asked', 8),\n",
       " ('than', 8),\n",
       " ('before', 8),\n",
       " ('because', 7),\n",
       " ('carried', 7),\n",
       " ('current', 7),\n",
       " ('not', 6),\n",
       " ('going', 5),\n",
       " ('too', 5),\n",
       " ('hundred', 5),\n",
       " ('hours', 5),\n",
       " ('circling', 5),\n",
       " ('where', 4),\n",
       " ('years', 4),\n",
       " ('it', 4),\n",
       " ('strange', 4),\n",
       " ('fisherman', 4),\n",
       " ('getting', 4),\n",
       " ('africa', 4),\n",
       " ('beaches', 4),\n",
       " ('strength', 4),\n",
       " ('that', 4),\n",
       " ('jump', 4),\n",
       " ('of', 3),\n",
       " ('take', 3),\n",
       " ('with', 3),\n",
       " ('does', 3),\n",
       " ('a', 3),\n",
       " ('i', 3),\n",
       " ('different', 3),\n",
       " ('gently', 3),\n",
       " ('difference', 3),\n",
       " ('our', 3),\n",
       " ('their', 2),\n",
       " ('edge', 2),\n",
       " ('you', 2),\n",
       " ('tell', 2),\n",
       " ('we', 2),\n",
       " ('put', 2),\n",
       " ('needed', 2),\n",
       " ('blanket', 2),\n",
       " ('dimaggio', 2),\n",
       " ('wanted', 2),\n",
       " ('great', 2),\n",
       " ('horses', 2),\n",
       " ('most', 2),\n",
       " ('he', 2),\n",
       " ('urinated', 2),\n",
       " ('carrying', 2),\n",
       " ('today', 2),\n",
       " ('began', 2),\n",
       " ('close', 2),\n",
       " ('cruel', 2),\n",
       " ('huge', 2),\n",
       " ('dropped', 2),\n",
       " ('am', 2),\n",
       " ('would', 2),\n",
       " ('drew', 2),\n",
       " ('empty', 1),\n",
       " ('were', 1),\n",
       " ('length', 1),\n",
       " ('odour', 1),\n",
       " ('play', 1),\n",
       " ('banging', 1),\n",
       " ('feeling', 1),\n",
       " (\"i'd\", 1),\n",
       " ('gamble', 1),\n",
       " ('confidence', 1),\n",
       " ('freshening', 1),\n",
       " ('rises', 1),\n",
       " (\"didn't\", 1),\n",
       " ('this', 1),\n",
       " ('old', 1),\n",
       " ('there', 1),\n",
       " ('go', 1),\n",
       " ('other', 1),\n",
       " ('beside', 1),\n",
       " ('place', 1),\n",
       " ('sacred', 1),\n",
       " ('read', 1),\n",
       " (\"yesterday's\", 1),\n",
       " ('fifth', 1),\n",
       " ('record', 1),\n",
       " ('half', 1),\n",
       " ('spread', 1),\n",
       " ('shoulders', 1),\n",
       " ('faded', 1),\n",
       " ('live', 1),\n",
       " ('care', 1),\n",
       " ('martin', 1),\n",
       " ('sent', 1),\n",
       " ('two', 1),\n",
       " ('eat', 1),\n",
       " ('village', 1),\n",
       " ('water', 1),\n",
       " ('towel', 1),\n",
       " ('another', 1),\n",
       " ('naturally', 1),\n",
       " ('sisler', 1),\n",
       " ('those', 1),\n",
       " ('remember', 1),\n",
       " ('lives', 1),\n",
       " (\"sisler's\", 1),\n",
       " ('age', 1),\n",
       " ('john', 1),\n",
       " ('jota', 1),\n",
       " ('difficult', 1),\n",
       " ('frequently', 1),\n",
       " ('times', 1),\n",
       " ('his', 1),\n",
       " ('trousers', 1),\n",
       " ('putting', 1),\n",
       " ('dressed', 1),\n",
       " ('harbours', 1),\n",
       " ('contests', 1),\n",
       " ('places', 1),\n",
       " ('foot', 1),\n",
       " ('milk', 1),\n",
       " ('cans', 1),\n",
       " ('confident', 1),\n",
       " ('credit', 1),\n",
       " ('out', 1),\n",
       " ('each', 1),\n",
       " ('as', 1),\n",
       " ('trembling', 1),\n",
       " ('friends', 1),\n",
       " ('voices', 1),\n",
       " ('did', 1),\n",
       " ('seventy', 1),\n",
       " ('twenty', 1),\n",
       " ('yellow', 1),\n",
       " ('jack', 1),\n",
       " ('rowed', 1),\n",
       " ('rather', 1),\n",
       " ('luck', 1),\n",
       " ('comes', 1),\n",
       " ('trying', 1),\n",
       " ('use', 1),\n",
       " ('desperately', 1),\n",
       " ('one', 1),\n",
       " ('ineffectually', 1),\n",
       " ('perhaps', 1),\n",
       " ('light', 1),\n",
       " ('iridescent', 1),\n",
       " ('gelatinous', 1),\n",
       " ('floated', 1),\n",
       " ('cheerfully', 1),\n",
       " ('drifted', 1),\n",
       " ('purple', 1),\n",
       " ('walk', 1),\n",
       " ('hawk', 1),\n",
       " ('friendly', 1),\n",
       " ('about', 1),\n",
       " ('turtles', 1),\n",
       " ('trunk', 1),\n",
       " ('directions', 1),\n",
       " ('driving', 1),\n",
       " ('dipping', 1),\n",
       " ('said', 1),\n",
       " ('compact', 1),\n",
       " ('unintelligent', 1),\n",
       " ('tuna', 1),\n",
       " ('could', 1),\n",
       " ('but', 1),\n",
       " ('well', 1),\n",
       " ('tentative', 1),\n",
       " ('gentle', 1),\n",
       " ('knew', 1),\n",
       " ('moving', 1),\n",
       " ('pivoted', 1),\n",
       " ('hack', 1),\n",
       " ('sounds', 1),\n",
       " ('dies', 1),\n",
       " ('drank', 1),\n",
       " ('rested', 1),\n",
       " ('pull', 1),\n",
       " ('like', 1),\n",
       " ('direction', 1),\n",
       " ('actually', 1),\n",
       " (\"fish's\", 1),\n",
       " ('want', 1),\n",
       " ('porpoises', 1),\n",
       " ('acted', 1),\n",
       " ('by', 1),\n",
       " ('jumping', 1),\n",
       " ('is', 1),\n",
       " ('exhausted', 1),\n",
       " ('scythe', 1),\n",
       " ('preparing', 1),\n",
       " ('fish', 1),\n",
       " ('jumped', 1),\n",
       " ('promptly', 1),\n",
       " ('joined', 1),\n",
       " ('gets', 1),\n",
       " ('catalan', 1),\n",
       " ('took', 1),\n",
       " ('hook', 1),\n",
       " ('once', 1),\n",
       " ('adjusted', 1),\n",
       " ('favorable', 1),\n",
       " ('tension', 1),\n",
       " ('jerk', 1),\n",
       " ('toward', 1),\n",
       " ('low', 1),\n",
       " ('over', 1),\n",
       " ('tired', 1),\n",
       " ('what', 1),\n",
       " ('hawks', 1),\n",
       " ('soon', 1),\n",
       " ('encouraged', 1),\n",
       " ('line', 1),\n",
       " ('jerked', 1),\n",
       " ('longitudinally', 1),\n",
       " ('next', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted({word: len(mismatches_i) for word, mismatches_i in mismatches.items()}.items(),\n",
    "       key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977400a0-92a4-4336-82a5-d8649ec64ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f7599a4-b6b4-49f4-9e61-08e22d672058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(mismatches_i) for mismatches_i in mismatches.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c586eb5b-98ec-4cf5-b96a-696e3076fc9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'him': ['ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m dʒ',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'h ɪ m dʒ',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m',\n",
       "              'ɪ m'],\n",
       "             'the': ['ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'v ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'dʒ ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð i',\n",
       "              'ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð ʌ dʒ',\n",
       "              'ð i',\n",
       "              'ʌ',\n",
       "              'd ð ʌ',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'ð i',\n",
       "              'd ð i',\n",
       "              'ð i',\n",
       "              'd ð ʌ',\n",
       "              'ð i',\n",
       "              'ð i'],\n",
       "             'and': ['ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'n d',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'æ n d',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n',\n",
       "              'ʌ n'],\n",
       "             'empty': ['ɛ m t i'],\n",
       "             'from': ['f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m',\n",
       "              'f ɚ m'],\n",
       "             'they': ['d ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ',\n",
       "              'd ð ɛɪ'],\n",
       "             'were': ['d w ɚ'],\n",
       "             'then': ['d ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              't ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              't ð ɛ n',\n",
       "              't ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              'd ð ɛ n',\n",
       "              't ð ɛ n'],\n",
       "             'because': ['b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z',\n",
       "              'b ɪ k ɑ z'],\n",
       "             'can': ['k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n',\n",
       "              'k ʌ n'],\n",
       "             'of': ['d ʌ v', 'dʒ ʌ', 'dʒ ʌ v'],\n",
       "             'carried': ['d k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d',\n",
       "              'k ɛ ɹ i d'],\n",
       "             'them': ['ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m',\n",
       "              'ð ʌ m'],\n",
       "             'length': ['l ɛ ŋ θ'],\n",
       "             'where': ['h w ɛ ɹ', 'h w ɛ ɹ', 'h w ɛ ɹ', 'h w ɛ ɹ'],\n",
       "             'their': ['d ð ɛ ɹ', 'd ð ɛ ɹ'],\n",
       "             'into': ['ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ',\n",
       "              'ɪ n t ʌ'],\n",
       "             'when': ['h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'h w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n',\n",
       "              'w ɪ n'],\n",
       "             'edge': ['ɛ', 'ɛ'],\n",
       "             'odour': ['ɑ d ʌ ɹ'],\n",
       "             'years': ['j ɚ z', 'j ɚ z', 'j ɚ z', 'j ɚ z'],\n",
       "             'get': ['g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'd g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t',\n",
       "              'g ɪ t'],\n",
       "             'play': ['d p l ɛɪ'],\n",
       "             'will': ['w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'aɪ w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l',\n",
       "              'w ʌ l'],\n",
       "             'you': ['d j u', 'd j'],\n",
       "             'banging': ['d b æ ŋ ɪ ŋ'],\n",
       "             'feeling': ['d f i l ɪ ŋ'],\n",
       "             'just': ['dʒ ɪ s',\n",
       "              'dʒ ʌ s',\n",
       "              'ɪ s t',\n",
       "              'ʌ s',\n",
       "              'ʌ s t',\n",
       "              'ʌ s',\n",
       "              'ʌ s t',\n",
       "              'ʌ s t',\n",
       "              'dʒ ʌ s'],\n",
       "             'tell': ['t t ɛ l', 'd t ɛ l'],\n",
       "             'it': ['ɪ t t', 'd ɪ t', 'd ɪ t', 'ɪ t t'],\n",
       "             'to': ['ʌ',\n",
       "              'ʌ',\n",
       "              'ʌ',\n",
       "              'd t ʌ',\n",
       "              'ʌ',\n",
       "              'ʌ',\n",
       "              'd t ʌ',\n",
       "              'ʌ',\n",
       "              't ʌ dʒ',\n",
       "              't t ʌ'],\n",
       "             \"i'd\": ['aɪ d t'],\n",
       "             'take': ['ɛɪ k', 't ɛɪ k k', 'ɛɪ k'],\n",
       "             'gamble': ['d g æ m b ʌ l'],\n",
       "             'your': ['d j ɔ ɹ',\n",
       "              'j ʊ ɹ',\n",
       "              'd j ɔ ɹ',\n",
       "              'j ʊ ɹ',\n",
       "              'j ʊ ɹ',\n",
       "              'j ʊ ɹ',\n",
       "              'j ʊ ɹ',\n",
       "              'j ʊ ɹ'],\n",
       "             'are': ['u ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɚ',\n",
       "              'ɑ ɹ dʒ',\n",
       "              'ɚ',\n",
       "              'ɚ'],\n",
       "             'confidence': ['k ɑ n f ʌ d ʌ n s'],\n",
       "             'freshening': ['f ɹ ɛ ʃ n ɪ ŋ'],\n",
       "             'rises': ['ɹ aɪ z ɪ z'],\n",
       "             \"didn't\": ['d ɪ d n t'],\n",
       "             'going': ['g oʊ ɪ n',\n",
       "              'g oʊ ɪ n',\n",
       "              'g oʊ ɪ n',\n",
       "              'g oʊ ɪ n',\n",
       "              'g oʊ ɪ n'],\n",
       "             'with': ['w ɪ ð ð', 'w ɪ ð ð', 'w ɪ ð ð'],\n",
       "             'this': ['ɪ s'],\n",
       "             'current': ['k ɑ ɹ ʌ n t',\n",
       "              'k ɑ ɹ ʌ n t',\n",
       "              'k ɚ n t',\n",
       "              'k ɑ ɹ ʌ n t',\n",
       "              'k ɑ ɹ ʌ n t',\n",
       "              'k ɑ ɹ ʌ n t',\n",
       "              'k ɑ ɹ ʌ n t'],\n",
       "             'asked': ['æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t',\n",
       "              'æ s t'],\n",
       "             'does': ['d ɪ z', 'd ɪ z', 'd ʌ z dʒ'],\n",
       "             'strange': ['s t ɹ ɛɪ n',\n",
       "              's t ɹ ɛɪ n',\n",
       "              's t ɹ ɛɪ n',\n",
       "              's t ɹ ɛɪ n'],\n",
       "             'old': ['dʒ oʊ l d'],\n",
       "             'there': ['d ð ɛ ɹ'],\n",
       "             'go': ['d g oʊ'],\n",
       "             'other': ['ʌ ʌ ð ɚ'],\n",
       "             'beside': ['b i s aɪ d'],\n",
       "             'a': ['d', 'd', 'ɛɪ'],\n",
       "             'place': ['ʌ p l ɛɪ s'],\n",
       "             'sacred': ['s ɛɪ k ɹ ʌ d'],\n",
       "             'or': ['ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ',\n",
       "              'ɔ ɹ'],\n",
       "             'i': ['d', 'd aɪ', 'dʒ aɪ'],\n",
       "             'read': ['ɹ i d'],\n",
       "             \"yesterday's\": ['j ɛ s t ɚ d i z'],\n",
       "             'we': ['d w i', 'w i i'],\n",
       "             'fifth': ['f ɪ θ'],\n",
       "             'record': ['ɹ ɛ k ɚ d'],\n",
       "             'half': ['ʌ h æ f'],\n",
       "             'fisherman': ['f ɪ ʃ ɚ m ʌ n',\n",
       "              'f ɪ ʃ ɚ m ʌ n',\n",
       "              'f ɪ ʃ ɚ m ʌ n',\n",
       "              'f ɪ ʃ ɚ m ʌ n'],\n",
       "             'spread': ['d s p ɹ ɛ d'],\n",
       "             'shoulders': ['dʒ ʃ oʊ l d ɚ z'],\n",
       "             'too': ['t u ʌ', 't u ʌ', 't u ʌ', 't u ʌ', 't u ʌ'],\n",
       "             'faded': ['f ɛɪ d ɪ d'],\n",
       "             'different': ['d ɪ f ɹ ʌ n t', 'd ɪ f ɹ ʌ n t', 'd ɪ f ɹ ʌ n t'],\n",
       "             'put': ['d p ʊ t', 'd p ʊ t'],\n",
       "             'getting': ['g ɪ t ɪ ŋ', 'g ɪ t ɪ ŋ', 'g ɪ t ɪ ŋ', 'g ɪ t ɪ ŋ'],\n",
       "             'live': ['l ɪ v'],\n",
       "             'care': ['ɛ ɹ'],\n",
       "             'martin': ['m ɑ ɹ t ɪ n'],\n",
       "             'has': ['h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z',\n",
       "              'h ʌ z'],\n",
       "             'for': ['f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ',\n",
       "              'f ɔ ɹ'],\n",
       "             'than': ['ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n',\n",
       "              'ð ʌ n'],\n",
       "             'sent': ['s ɛ n t t'],\n",
       "             'two': ['u'],\n",
       "             'eat': ['t'],\n",
       "             'gently': ['ɛ n t l i', 'ɛ n t l i', 'ɛ n t l i'],\n",
       "             'needed': ['n i d ɪ d', 'n i d ɪ d'],\n",
       "             'village': ['v ɪ l ɪ'],\n",
       "             'water': ['dʒ w ɔ t ɚ'],\n",
       "             'towel': ['t aʊ l'],\n",
       "             'another': ['d ʌ n ʌ ð ɚ'],\n",
       "             'blanket': ['b l æ ŋ k ɪ t', 'b l æ ŋ k ɪ t'],\n",
       "             'dimaggio': ['d ɪ m æ i u', 'd ɪ m æ i u'],\n",
       "             'naturally': ['n æ tʃ ɹ ʌ l i'],\n",
       "             'difference': ['d ɪ f ɹ ʌ n s', 'd ɪ f ɹ ʌ n s', 'd ɪ f ɹ ʌ n s'],\n",
       "             'sisler': ['s ɪ s l ɚ'],\n",
       "             'those': ['d ð oʊ z'],\n",
       "             'remember': ['ɹ i m ɛ m b ɚ'],\n",
       "             'wanted': ['w ɔ n ɪ d', 'w ɑ n t ʌ d'],\n",
       "             'our': ['ɑ ɹ', 'ɑ ɹ', 'ɑ ɹ'],\n",
       "             'lives': ['l aɪ v z'],\n",
       "             \"sisler's\": ['s ɪ s ʌ l ɚ z'],\n",
       "             'age': ['ɛɪ'],\n",
       "             'africa': ['æ f ɹ ʌ k ʌ',\n",
       "              'æ f ɹ ʌ k ʌ',\n",
       "              'æ f ɹ ʌ k ʌ',\n",
       "              'æ f ɹ ʌ k ʌ'],\n",
       "             'beaches': ['b i tʃ ɪ z',\n",
       "              'b i tʃ ɪ z',\n",
       "              'b i tʃ ɪ z',\n",
       "              'b i tʃ ɪ z'],\n",
       "             'great': ['g ɹ ɛɪ t dʒ', 'g ɹ ɛɪ t t'],\n",
       "             'john': ['ɑ n'],\n",
       "             'jota': ['u t ʌ'],\n",
       "             'difficult': ['d d ɪ f ʌ k ʌ l t'],\n",
       "             'horses': ['h ɔ ɹ s ɪ z', 'h ɔ ɹ s ɪ z'],\n",
       "             'frequently': ['f ɹ i k w ɛ n t l i'],\n",
       "             'most': ['m oʊ s', 'm oʊ s'],\n",
       "             'times': ['t t aɪ m z'],\n",
       "             'his': ['h ɪ'],\n",
       "             'trousers': ['z t ɹ aʊ z ɚ z'],\n",
       "             'putting': ['p ʊ t ɪ ŋ'],\n",
       "             'dressed': ['d d ɹ ɛ s t'],\n",
       "             'harbours': ['h ɑ ɹ b u j ʌ ɹ z'],\n",
       "             'contests': ['k ɑ n t ɛ s'],\n",
       "             'strength': ['s t ɹ ɛ ŋ θ',\n",
       "              's t ɹ ɛ ŋ θ',\n",
       "              's t ɹ ɛ ŋ θ',\n",
       "              's t ɹ ɛ ŋ θ'],\n",
       "             'places': ['p l ɛɪ s ɪ z'],\n",
       "             'he': ['d h i', 'd h i'],\n",
       "             'urinated': ['j ʊ ɹ ʌ n ɛɪ t ɪ d', 'j ʊ ɹ ʌ n ɛɪ t ɪ d'],\n",
       "             'that': ['d ð ʌ t', 'd ð ʌ t', 'ð ʌ t t', 'ð æ t t'],\n",
       "             'foot': ['f ʊ t dʒ'],\n",
       "             'carrying': ['k ɛ ɹ i ɪ ŋ', 'k ɛ ɹ i ɪ ŋ'],\n",
       "             'milk': ['m ɪ l k k'],\n",
       "             'cans': ['æ n z'],\n",
       "             'confident': ['k ɑ n f ʌ d ʌ n t t'],\n",
       "             'today': ['ʌ d ɛɪ', 'ʌ d ɛɪ'],\n",
       "             'credit': ['k ɹ ɛ d ɪ t'],\n",
       "             'began': ['b i g æ n', 'b i g æ n'],\n",
       "             'out': ['aʊ t t'],\n",
       "             'each': ['d i tʃ'],\n",
       "             'close': ['k l oʊ z', 'k l oʊ z'],\n",
       "             'as': ['d ɛ z'],\n",
       "             'trembling': ['t ɹ ɛ m b l ɪ ŋ'],\n",
       "             'friends': ['f ɹ ɛ n z'],\n",
       "             'cruel': ['k ɹ u l', 'k ɹ u l'],\n",
       "             'voices': ['v ɔɪ s ɪ z'],\n",
       "             'did': ['d d ɪ d'],\n",
       "             'seventy': ['s ɛ v ʌ n i'],\n",
       "             'hundred': ['h ʌ n d ɚ d',\n",
       "              'h ʌ n d ɹ ɪ d',\n",
       "              'h ʌ n d ɹ ɪ d',\n",
       "              'h ʌ n d ɹ ɪ d',\n",
       "              'h ʌ n ɚ d'],\n",
       "             'twenty': ['t w ɛ n i'],\n",
       "             'yellow': ['j ɛ l oʊ dʒ'],\n",
       "             'jack': ['æ k'],\n",
       "             'before': ['b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ',\n",
       "              'b i f ɔ ɹ'],\n",
       "             'rowed': ['ɹ oʊ d dʒ'],\n",
       "             'rather': ['ɹ ʌ ð ɚ'],\n",
       "             'luck': ['l ʌ k k'],\n",
       "             'comes': ['ʌ m z'],\n",
       "             'hours': ['aʊ ɹ z', 'aʊ ɹ z', 'aʊ ɹ z', 'aʊ ɹ z', 'aʊ ɹ z'],\n",
       "             'circling': ['s ɚ k l ɪ ŋ',\n",
       "              's ɚ k l ɪ ŋ',\n",
       "              's ɚ k l ɪ ŋ',\n",
       "              's ɚ k l ɪ ŋ',\n",
       "              's ɚ k l ɪ ŋ'],\n",
       "             'not': ['n ɑ t dʒ',\n",
       "              'n ɑ t t',\n",
       "              'n ɑ t t',\n",
       "              'n ɑ t t',\n",
       "              'n ɑ t t',\n",
       "              'n ɑ t dʒ'],\n",
       "             'trying': ['ɹ aɪ ŋ'],\n",
       "             'use': ['j u z'],\n",
       "             'desperately': ['d ɛ s p ɹ ʌ t l i'],\n",
       "             'one': ['h w ʌ n'],\n",
       "             'ineffectually': ['ɪ n ɪ f ɛ k tʃ ʌ w ʌ l i'],\n",
       "             'perhaps': ['d p ɚ h æ p s'],\n",
       "             'light': ['dʒ l aɪ t'],\n",
       "             'iridescent': ['ɪ ɹ ʌ d ɛ s ʌ n t dʒ'],\n",
       "             'gelatinous': ['ʌ l æ t ʌ n ʌ s'],\n",
       "             'floated': ['f l oʊ t ɪ d'],\n",
       "             'cheerfully': ['tʃ ɪ ɹ f l i'],\n",
       "             'drifted': ['d ɹ ɪ f t ɪ d'],\n",
       "             'purple': ['d p ɚ p ʌ l'],\n",
       "             'walk': ['w ɑ k'],\n",
       "             'hawk': ['h ɔ k s'],\n",
       "             'friendly': ['f ɹ ɛ n l i'],\n",
       "             'huge': ['j u dʒ', 'j u dʒ'],\n",
       "             'about': ['ʌ b aʊ t t'],\n",
       "             'turtles': ['ɚ t ʌ l z'],\n",
       "             'trunk': ['ɹ ʌ ŋ k'],\n",
       "             'dropped': ['d d ɹ ɑ p t', 'd d ɹ ɑ p t'],\n",
       "             'directions': ['d ɪ ɹ ɛ k ʃ ɪ n z'],\n",
       "             'driving': ['d d ɹ aɪ v ɪ ŋ'],\n",
       "             'dipping': ['d d ɪ p ɪ ŋ'],\n",
       "             'said': ['s ɛ d dʒ'],\n",
       "             'compact': ['k ʌ m p æ k t'],\n",
       "             'unintelligent': ['ʌ n ɪ n t ɛ l ʌ ʌ n t'],\n",
       "             'tuna': ['t j u n ʌ'],\n",
       "             'could': ['k ʊ d dʒ'],\n",
       "             'but': ['b ʌ t t'],\n",
       "             'well': ['w ɛ l dʒ'],\n",
       "             'tentative': ['t ɛ n ʌ t ɪ v'],\n",
       "             'gentle': ['ɛ n t ʌ l'],\n",
       "             'knew': ['n u h'],\n",
       "             'moving': ['u v ɪ ŋ'],\n",
       "             'pivoted': ['p ɪ v ʌ t ʌ d'],\n",
       "             'hack': ['b æ k'],\n",
       "             'sounds': ['s aʊ n z'],\n",
       "             'dies': ['d d aɪ z'],\n",
       "             'drank': ['d d ɹ æ ŋ k'],\n",
       "             'rested': ['ɹ ɛ s t ɪ d'],\n",
       "             'pull': ['p ʊ l l'],\n",
       "             'like': ['aɪ k'],\n",
       "             'direction': ['d ɪ ɹ ɛ k ʃ ɪ n'],\n",
       "             'actually': ['æ k tʃ l i'],\n",
       "             \"fish's\": ['f ɪ ʃ s'],\n",
       "             'want': ['w ɑ n t t'],\n",
       "             'porpoises': ['p ɔ ɹ p ʌ s'],\n",
       "             'acted': ['æ k t ʌ d'],\n",
       "             'jump': ['ʌ m p', 'ʌ m p', 'ʌ m p', 'ʌ m p'],\n",
       "             'by': ['b aɪ dʒ'],\n",
       "             'jumping': ['ʌ m p ɪ ŋ'],\n",
       "             'is': ['ɪ z dʒ'],\n",
       "             'am': ['ɛɪ ɛ m', 'ɛɪ ɛ m'],\n",
       "             'exhausted': ['ɪ g z ɔ s t ʌ d'],\n",
       "             'scythe': ['s aɪ θ'],\n",
       "             'preparing': ['p ɚ p ɛ ɹ ɪ ŋ'],\n",
       "             'fish': ['f ɪ ʃ dʒ'],\n",
       "             'jumped': ['ʌ m p t'],\n",
       "             'promptly': ['p ɹ ɑ m p l i'],\n",
       "             'joined': ['ɔɪ n d'],\n",
       "             'gets': ['g ɪ t s'],\n",
       "             'catalan': ['k æ t ʌ l ʌ n'],\n",
       "             'took': ['ʊ k'],\n",
       "             'hook': ['d h ʊ k'],\n",
       "             'once': ['d w ʌ n s'],\n",
       "             'adjusted': ['ʌ dʒ ʌ s t ʌ d'],\n",
       "             'favorable': ['f ɛɪ v ɹ ʌ b ʌ l'],\n",
       "             'would': ['w ʊ d dʒ', 'd w ʊ d'],\n",
       "             'tension': ['t ɛ n ʃ ʌ n dʒ'],\n",
       "             'jerk': ['ɚ k'],\n",
       "             'toward': ['t ɔ ɹ d'],\n",
       "             'low': ['l oʊ oʊ'],\n",
       "             'over': ['v ɚ'],\n",
       "             'tired': ['aɪ ɚ d'],\n",
       "             'what': ['h w ʌ t'],\n",
       "             'hawks': ['h ɔ k s s'],\n",
       "             'soon': ['u n'],\n",
       "             'encouraged': ['ɪ n k ɚ ʌ dʒ d'],\n",
       "             'line': ['l aɪ n dʒ'],\n",
       "             'jerked': ['ɚ k t'],\n",
       "             'drew': ['d d ɹ u', 'd d ɹ u'],\n",
       "             'longitudinally': ['l ɑ n ʌ t ʌ d ʌ n ʌ l i'],\n",
       "             'next': ['n ɛ k s']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71eaa4e-8880-4e43-bd14-b6656d1e7bce",
   "metadata": {},
   "source": [
    "## Compute stimulus representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5862884-7254-4c62-a364-52e859322832",
   "metadata": {},
   "source": [
    "### Prepare phoneme-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ae0b6e-909f-46be-8899-fbe4539f6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CohortPredictiveModel:\n",
    "    \"\"\"\n",
    "    A model of phoneme probabilities which incorporates a lexical frequency prior\n",
    "    together with a 0-1 cohort likelihood.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lexicon_items: List[WordForm]):\n",
    "        # Compute a unigram phoneme frequency distribution\n",
    "        # Also simultaneously compute cohorts (sets of words compatible with prefix)\n",
    "        phoneme_freqs, cohorts = Counter(), defaultdict(set)\n",
    "        for ipa_word in lexicon_items:\n",
    "            phoneme_freqs.update(ipa_word)\n",
    "            for prefix in range(len(ipa_word)):\n",
    "                cohorts[tuple(ipa_word[:prefix])].add(ipa_word)\n",
    "                \n",
    "        self._unigram_phoneme_distribution = pd.Series(phoneme_freqs)\n",
    "        self._unigram_phoneme_distribution /= self._unigram_phoneme_distribution.sum()\n",
    "        \n",
    "        self._cohorts = {prefix: list(cohort) for prefix, cohort in cohorts.items()}\n",
    "        \n",
    "    def cohort_distribution(self, ipa_prefix: WordForm, pad_phoneme=\"_\") -> Optional[pd.DataFrame]:\n",
    "        cohort_words = self._cohorts.get(ipa_prefix, [])\n",
    "        if not cohort_words:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99504c0a-7943-445b-8c27-9758263c36c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_to_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m word, phonemes \u001b[38;5;241m=\u001b[39m \u001b[43mword_to_token\u001b[49m[\u001b[38;5;241m1\u001b[39m], ground_truth_phonemes[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m word, phonemes\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Mixture parameter for conditional and unigram phoneme distributions when computing phoneme probabilities\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# TODO tune?\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_to_token' is not defined"
     ]
    }
   ],
   "source": [
    "# word, phonemes = word_to_token[1], ground_truth_phonemes[1]\n",
    "# word, phonemes\n",
    "\n",
    "# # Mixture parameter for conditional and unigram phoneme distributions when computing phoneme probabilities\n",
    "# # TODO tune?\n",
    "# gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdfbdb-3427-482c-a846-13138fbeb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cohort_distribution(ipa_prefix, pad_phoneme=\"_\"):\n",
    "#     cohort_words =\n",
    "\n",
    "# def cohort_phoneme_distribution(ipa_prefix, pad_phoneme=\"_\"):\n",
    "#     df = cohort_distribution(ipa_prefix, pad_phoneme=pad_phoneme)\n",
    "#     if df is None:\n",
    "#         # Back off to unigram distribution\n",
    "#         return _unigram_phoneme_distribution\n",
    "    \n",
    "#     ps = df.groupby(\"next\").p.sum()\n",
    "#     # mix with phoneme unigram distribution\n",
    "#     gamma = 0.1\n",
    "#     ps = (1 - gamma) * ps\n",
    "#     ps = ps.add(gamma * _unigram_phoneme_distribution, fill_value=0)\n",
    "#     ps /= ps.sum()\n",
    "#     return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5403c-0de0-4667-a722-c3e8c24a3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprisals, entropies = [], []\n",
    "# for prefix_length in range(len(phonemes) + 1):\n",
    "#     prefix = \"\".join(phonemes[:prefix_length])\n",
    "    \n",
    "#     if prefix_length == len(phonemes):\n",
    "#         # Only compute posterior entropy\n",
    "#         surprisal = 0\n",
    "#         dist_prev = cohort_phoneme_distribution(prefix)\n",
    "#         entropy = (dist_prev * -np.log2(dist_prev)).sum()\n",
    "#     else:\n",
    "#         # Compute surprisal and entropy\n",
    "#         surprisal, entropy = phoneme_surprisal_entropy(prefix, phonemes[prefix_length])\n",
    "        \n",
    "#     surprisals.append(surprisal)\n",
    "#     entropies.append(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77efdeaf-59c4-45b1-96ec-fe412783ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllable onsets are technically phoneme-level features!\n",
    "syllable_tokenizer = english.IPASyllableTokenizer()\n",
    "\n",
    "def compute_syllable_onset_idxs(phonemes) -> List[int]:\n",
    "    \"\"\"\n",
    "    Compute the phoneme indices which constitute the start of a new syllable.\n",
    "    \"\"\"\n",
    "    syllables = syllable_tokenizer.tokenize(phonemes)\n",
    "    syllable_onset_idxs = [0] + list(np.cumsum([len(syll) for syll in syllables])[:-1])\n",
    "    \n",
    "    return syllable_onset_idxs\n",
    "\n",
    "def compute_phoneme_features(phonemes, syllable_onset_idxs):\n",
    "    # Add syllable onset feature\n",
    "    ret_features = torch.zeros((len(phonemes), 1))\n",
    "    ret_features[syllable_onset_idxs, 0] = 1.\n",
    "    \n",
    "    return ret_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c7f8e-ca43-43f4-898a-af3d671c9f09",
   "metadata": {},
   "source": [
    "### Run stimulus processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1943467c-1fc0-4687-aba8-938b10f5910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "WARNING:root:Tokenizer is missing pad token; using EOS token <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "PAD_PHONEME = \"_\"\n",
    "proc = NaturalLanguageStimulusProcessor(phonemes=list(dict_ipa_chars) + [PAD_PHONEME],\n",
    "                                        hf_model=model,\n",
    "                                        num_candidates=n_candidates,\n",
    "                                        phonemizer=phonemizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4beeadb8-445b-4ebb-8bdf-da42394717f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8db7c54-42e3-40b8-96a5-72e345104dad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14931ef548024f43b9d424bbcaef7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?run/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93abf7640e464955a689b7add99975ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run, run_words in tqdm(words_df.groupby(\"run\"), unit=\"run\"):\n",
    "    run_phonemes = phonemes_df.loc[run]\n",
    "    \n",
    "    # Prepare proc metadata input.\n",
    "    word_to_token = run_words.groupby(\"word_idx\") \\\n",
    "        .apply(lambda x: list(x.token_idx)).to_dict()\n",
    "    \n",
    "    ground_truth_phonemes = run_phonemes.groupby(\"word_idx\") \\\n",
    "        .apply(lambda xs: list(xs.phoneme)).to_dict()\n",
    "    \n",
    "    # Prepare word-level features.\n",
    "    word_features = dict(run_words.groupby(\"word_idx\").apply(lambda xs: torch.tensor(xs.iloc[0].log_freq).unsqueeze(0)))\n",
    "    word_feature_names = [\"word_frequency\"]\n",
    "    \n",
    "    phoneme_features = {}\n",
    "    syllable_onset_idxs = {}\n",
    "    phoneme_feature_names = [\"syllable_onset\"]\n",
    "    for word_idx in ground_truth_phonemes:\n",
    "        phonemes_i = ground_truth_phonemes[word_idx]\n",
    "        syllable_onset_idxs[word_idx] = compute_syllable_onset_idxs(phonemes_i)\n",
    "        phoneme_features[word_idx] = compute_phoneme_features(phonemes_i, syllable_onset_idxs[word_idx])\n",
    "        assert len(phoneme_feature_names) == phoneme_features[word_idx].shape[-1]\n",
    "    \n",
    "    # NB `tokens` contains tokens from all runs. so we'll actually be \n",
    "    # processing way too much per run. but it's okay I think\n",
    "    \n",
    "    stim = proc(f\"{story_name}/run{run}\", tokens, word_to_token,\n",
    "                word_features, word_feature_names,\n",
    "                phoneme_features, phoneme_feature_names,\n",
    "                ground_truth_phonemes)\n",
    "    \n",
    "    # Add syllable onset annotation\n",
    "    if stim.word_events is None:\n",
    "        stim.word_events = {}\n",
    "    stim.word_events[\"syllable_onset\"] = [syllable_onset_idxs[word_id.item()]\n",
    "                                          for word_id in stim.word_ids]\n",
    "    \n",
    "    with (Path(output_dir) / f\"run{run}.pkl\").open(\"wb\") as f:\n",
    "        pickle.dump(stim, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
