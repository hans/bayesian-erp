{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e10df71a-1a18-4cc8-9463-5522488bdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c779d9-57dd-43e3-af30-a3c771bfa620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(str(Path(\".\").resolve().parent.parent))\n",
    "\n",
    "from berp.datasets import BerpDataset, NestedBerpDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17f23ec3-6058-44e8-92b5-5b6dc07794a3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "story_name = \"old-man-and-the-sea\"\n",
    "subject = 1\n",
    "run = 2\n",
    "\n",
    "aligned_words = \"word.csv\"\n",
    "aligned_phonemes = \"phoneme.csv\"\n",
    "\n",
    "stimulus = \"old-man-and-the-sea/run2.pkl\"\n",
    "\n",
    "# run_Xy = \"../../workflow/heilbron2022/data/run_Xy/old-man-and-the-sea/sub1/run1.h5\"\n",
    "run_Xy = \"/home/jgauthie/om2/others/heilbron2022/notebooks/exported/Xy/words_proba/sub1/run2.h5\"\n",
    "\n",
    "target_sample_rate = 128\n",
    "output_path = \"old-man-and-the-sea.sub1.run2.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282c557-9417-4f5f-987c-f817a5674a3d",
   "metadata": {},
   "source": [
    "## Load and process natural language stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb0eeef0-6754-4621-9596-dd88fd706031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(stimulus).open(\"rb\") as f:\n",
    "    story_stim = pickle.load(f)\n",
    "    \n",
    "assert story_stim.name == story_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fae48b57-9914-45d6-a2ec-b72ec57e684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable onset features are simply a variable onset intercept,\n",
    "# word features and word surprisals.\n",
    "X_variable = torch.concat(\n",
    "    [torch.ones_like(story_stim.word_surprisals).unsqueeze(1),\n",
    "     story_stim.word_features,\n",
    "     story_stim.word_surprisals.unsqueeze(1)],\n",
    "    dim=1)\n",
    "variable_feature_names = [\"recognition_onset\"] + story_stim.word_feature_names + [\"word_surprisal\"]\n",
    "\n",
    "assert X_variable.shape[1] == len(variable_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c3e68-268f-449d-8335-1eb36bc7be8b",
   "metadata": {},
   "source": [
    "## Load design matrix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2ca6f4b-73f1-4348-a976-eaa6c33ef3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(run_Xy) as f:\n",
    "    assert subject == f.attrs[\"subject\"]\n",
    "    assert run == f.attrs[\"run\"]\n",
    "    \n",
    "    X = f[\"X\"][()]\n",
    "    y = f[\"y\"][()].T\n",
    "    \n",
    "    sensor_names = f.attrs[\"ch_names\"]\n",
    "    ts_feature_names = f.attrs[\"feature_names\"]\n",
    "    sfreq = f.attrs[\"sfreq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d69879d-fdff-4d51-85b2-5f6846a0a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[0] == y.shape[0]\n",
    "assert X.shape[1] == len(ts_feature_names)\n",
    "assert y.shape[1] == len(sensor_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1034c5c6-4c60-476a-9741-76b25c3f0052",
   "metadata": {},
   "source": [
    "## Load aligned word/phoneme presentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb2dcb33-2431-40bf-88e3-0ae790c678bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>token_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>WHEN</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.31</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>THE</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.37</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WIND</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.61</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.77</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.87</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>541</td>\n",
       "      <td>AND</td>\n",
       "      <td>179.26</td>\n",
       "      <td>179.35</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>542</td>\n",
       "      <td>YOUR</td>\n",
       "      <td>179.35</td>\n",
       "      <td>179.56</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>543</td>\n",
       "      <td>EYES</td>\n",
       "      <td>179.56</td>\n",
       "      <td>179.77</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>544</td>\n",
       "      <td>ARE</td>\n",
       "      <td>179.77</td>\n",
       "      <td>179.83</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>545</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>179.83</td>\n",
       "      <td>180.16</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_idx  word   onset  offset  token_idx\n",
       "0           0  WHEN    1.17    1.31        688\n",
       "1           1   THE    1.31    1.37        689\n",
       "2           2  WIND    1.37    1.61        690\n",
       "3           3   WAS    1.61    1.77        691\n",
       "4           4    IN    1.77    1.87        692\n",
       "..        ...   ...     ...     ...        ...\n",
       "562       541   AND  179.26  179.35       1364\n",
       "563       542  YOUR  179.35  179.56       1365\n",
       "564       543  EYES  179.56  179.77       1366\n",
       "565       544   ARE  179.77  179.83       1367\n",
       "566       545  GOOD  179.83  180.16       1368\n",
       "\n",
       "[567 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_aligned_df = pd.read_csv(aligned_words, index_col=[0, 1]).loc[run].reset_index()\n",
    "phoneme_aligned_df = pd.read_csv(aligned_phonemes, index_col=[0, 1]).loc[run].reset_index()\n",
    "word_aligned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "989b45fe-c516-45cd-b84e-9abb6943b4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16,\n",
       " 46,\n",
       " 68,\n",
       " 116,\n",
       " 141,\n",
       " 170,\n",
       " 199,\n",
       " 227,\n",
       " 278,\n",
       " 301,\n",
       " 326,\n",
       " 349,\n",
       " 370,\n",
       " 399,\n",
       " 451,\n",
       " 503,\n",
       " 526}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Not all words in the presentation will be retained in the stimulus: words which\n",
    "# ended up at the start of an input time series to the model were dropped, because\n",
    "# the model didn't have those values as targets.\n",
    "#\n",
    "# By the above logic, the missing words will likely be distributed roughly evenly\n",
    "# throughout the stimulus.\n",
    "words_missing_in_stimulus = set(word_aligned_df.word_idx) - set(story_stim.word_ids.numpy())\n",
    "\n",
    "plt.figure(figsize=(15, 1))\n",
    "plt.hlines(0, 0, story_stim.word_ids.max())\n",
    "plt.plot(list(words_missing_in_stimulus), np.zeros(len(words_missing_in_stimulus)), 'ro', ms=8, mfc='r')\n",
    "plt.axis('off')\n",
    "plt.title(\"Words missing in stimulus representation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "words_missing_in_stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b10e29cc-d411-4899-b7a6-9226af994c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == len(set(story_stim.word_ids.numpy()) - set(word_aligned_df.word_idx)), \\\n",
    "    \"Stim words are present which are missing from the aligned data!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fe2be-bed9-44c1-a341-136a929d4df9",
   "metadata": {},
   "source": [
    "## Load signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1397bb9e-a151-458c-8f66-2066b30a7788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.7265625"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_time, max_time = 0, len(X) / sfreq\n",
    "max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8baf303e-3a30-4760-a47f-525f4f1feb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46, 134 chopped words/phonemes. Dropping.\n"
     ]
    }
   ],
   "source": [
    "# Check compatibility with alignment data.\n",
    "assert min_time <= word_aligned_df.onset.min()\n",
    "assert min_time <= phoneme_aligned_df.onset.min()\n",
    "\n",
    "# NB looks like the last sentence-ish of each run is truncated from the signal\n",
    "# data. TODO double check this with authors?\n",
    "# assert max_time >= word_aligned_df.offset.max()\n",
    "# assert max_time >= phoneme_aligned_df.offset.max()\n",
    "chopped_words = word_aligned_df.offset >= max_time\n",
    "chopped_phonemes = phoneme_aligned_df.offset >= max_time\n",
    "print(f\"{chopped_words.sum()}, {chopped_phonemes.sum()} chopped words/phonemes. Dropping.\")\n",
    "\n",
    "word_aligned_df = word_aligned_df[~chopped_words]\n",
    "phoneme_aligned_df = phoneme_aligned_df[~chopped_phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b12999f2-5d40-4580-89aa-1e8993247215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also dropping 1 orphaned phonemes.\n"
     ]
    }
   ],
   "source": [
    "# We may have residual phonemes without a corresponding word now. Remove those.\n",
    "orphaned_phonemes = ~phoneme_aligned_df.word_idx.isin(word_aligned_df.word_idx)\n",
    "if orphaned_phonemes.any():\n",
    "    print(f\"Also dropping {orphaned_phonemes.sum()} orphaned phonemes.\")\n",
    "    phoneme_aligned_df = phoneme_aligned_df[~orphaned_phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec525b5b-44ca-474e-928c-f3c79494091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency.\n",
    "assert set(word_aligned_df.word_idx) == set(phoneme_aligned_df.word_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a390af-4501-4259-957a-cae23e7c5584",
   "metadata": {},
   "source": [
    "## Produce BerpDataset representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ece3d43a-0108-45c3-a8bb-cff6272e26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now produce onset information from canonical aligned data.\n",
    "# NB this will contain NaNs if there was misalignment above.\n",
    "word_onsets = word_aligned_df.groupby(\"word_idx\").onset.min().to_dict()\n",
    "word_onsets = torch.tensor([word_onsets.get(word_id.item(), np.nan)\n",
    "                            for word_id in story_stim.word_ids])\n",
    "\n",
    "word_offsets = word_aligned_df.groupby(\"word_idx\").offset.max().to_dict()\n",
    "word_offsets = torch.tensor([word_offsets.get(word_id.item(), np.nan)\n",
    "                             for word_id in story_stim.word_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "788d22b9-a3df-41b3-b46f-4b025f4ebc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute phoneme onsets relative to word onset.\n",
    "phoneme_onsets = phoneme_aligned_df.groupby(\"word_idx\") \\\n",
    "    .apply(lambda xs: list(xs.onset - xs.onset.min())).to_dict()\n",
    "phoneme_onsets = [torch.tensor(phoneme_onsets.get(word_id.item(), [np.nan]))\n",
    "                  for word_id in story_stim.word_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b9f95a4-461a-41c8-b905-2d85627f0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_phonemes = max(len(onsets) for onsets in phoneme_onsets)\n",
    "# Sanity check: max_num_phonemes as computed from aligned data should\n",
    "# match that produced earlier by the natural language stimulus processor\n",
    "assert max_num_phonemes == story_stim.max_n_phonemes, \\\n",
    "    \"%d %d\" % (max_num_phonemes, story_stim.max_n_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bacdcad4-7106-495d-a484-37b6633a33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad phoneme onset information\n",
    "phoneme_onsets = torch.stack([\n",
    "    pad(onsets, (0, max_num_phonemes - len(onsets)), value=0.)\n",
    "    if len(onsets) < max_num_phonemes\n",
    "    else onsets\n",
    "    for onsets in phoneme_onsets\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75c95267-5d48-4270-ac19-59c8876ae342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BerpDataset(\n",
    "    name=f\"{story_name}/{subject}_{run}\",\n",
    "    stimulus_name=story_stim.name,\n",
    "    sample_rate=sfreq,\n",
    "    \n",
    "    phonemes=story_stim.phonemes,\n",
    "    \n",
    "    word_onsets=word_onsets,\n",
    "    word_offsets=word_offsets,\n",
    "    phoneme_onsets=phoneme_onsets,\n",
    "    \n",
    "    X_ts=X,\n",
    "    ts_feature_names=ts_feature_names,\n",
    "    \n",
    "    X_variable=X_variable,\n",
    "    variable_feature_names=variable_feature_names,\n",
    "    \n",
    "    Y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bfc08d54-edaa-4e43-9178-41b0251a2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(output_path).open(\"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
