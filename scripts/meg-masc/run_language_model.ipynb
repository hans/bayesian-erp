{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d0b0bb86-ac22-42dc-857d-05c0543fb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(str(Path(\".\").resolve().parent.parent))\n",
    "from berp.datasets import NaturalLanguageStimulusProcessor\n",
    "from berp.languages import english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0a4fb149-26b5-4d16-989e-4989f35cc353",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tokenized_path = \"lw1.tokenized.txt\"\n",
    "aligned_words_path = \"word.csv\"\n",
    "aligned_phonemes_path = \"phoneme.csv\"\n",
    "story_name = \"lw1\"\n",
    "\n",
    "cmu_ipa_dict_path = \"../../cmudict-0.7b-ipa.txt\"\n",
    "vocab_path = \"../../workflow/meg-masc/data/frequency/subtlexus2.csv\"\n",
    "\n",
    "output_path = \"lw1.pkl\"\n",
    "\n",
    "model = \"distilgpt2\"\n",
    "n_candidates = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bd384-11b6-4224-97fd-6b195e7afe3f",
   "metadata": {},
   "source": [
    "## Prepare tokenized data and aligned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "15ebaaa8-6f90-46c4-af17-2a38a5496f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Path(tokenized_path).read_text().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "507510e8-913b-4c86-835a-04e13b147f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_csv(aligned_words_path, index_col=0)\n",
    "phonemes_df = pd.read_csv(aligned_phonemes_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "815b8f20-fa3f-4222-9d38-c7e8f4584b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ah_I    119\n",
       "ih_I     98\n",
       "n_I      87\n",
       "t_E      77\n",
       "r_I      68\n",
       "       ... \n",
       "zh_I      1\n",
       "hh_I      1\n",
       "iy_B      1\n",
       "oy_E      1\n",
       "ch_B      1\n",
       "Name: phoneme, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The phonemes in this corpus are output from Gentle. The phoneme string representation is\n",
    "#\n",
    "# `<CMUDict_phoneme>_{B,I,E,S}`\n",
    "#\n",
    "# where B,I,E indicate that the phoneme is at the beginning, middle, and end of a word. S\n",
    "# indicates singleton (single-phoneme words).\n",
    "phonemes_df.phoneme.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d29f6cb7-26cc-4866-902d-0b2d1d33f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes_df[\"phoneme\"] = phonemes_df.phoneme.str.rstrip(r\"_[BIES]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3a04d79-6d63-436c-8630-eaeda0b69d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['t', 'eh', 'r', 'ah', 's', 'uh', 'd', 'aa', 'k', 'ih', 'l', 'w',\n",
       "       'ey', 'ng', 'f', 'er', 'dh', 'ay', 'n', 'iy', 'g', 'm', 'aw', 'ae',\n",
       "       'uw', 'p', 'v', 'jh', 'b', 'z', 'oy', 'hh', 'ow', 'sh', 'ao', 'th',\n",
       "       'ch', 'zh', 'y'], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes_df.phoneme.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b61d26-325b-4cd6-85cc-2c9e266d6fbf",
   "metadata": {},
   "source": [
    "## Prepare frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7fb29b52-c74f-4991-bd46-c63c3878ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_df = pd.read_csv(vocab_path, sep=\"\\t\")\n",
    "\n",
    "frequency_df[\"Word\"] = frequency_df.Word.str.lower()\n",
    "assert frequency_df.Word.value_counts().max() == 1\n",
    "\n",
    "frequency_df[\"log_freq\"] = -np.log2(frequency_df.FREQcount / frequency_df.FREQcount.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7afcba48-1626-48bb-8ec5-a957912e57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df[\"word_lower\"] = words_df.word.str.lower()\n",
    "old_size = len(words_df)\n",
    "words_df = pd.merge(words_df, frequency_df[[\"Word\", \"log_freq\"]], left_on=\"word_lower\", right_on=\"Word\",\n",
    "                    how=\"left\")\n",
    "assert len(words_df) == old_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b7a47c54-ff00-43e2-be6a-7a6f8646cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (0.006%) words missing frequency values.\n",
      "Replacing with 2-percentile log-frequency: 24.56731019333269\n"
     ]
    }
   ],
   "source": [
    "# Put words with missing frequency in the lowest 2 percentile.\n",
    "missing_freq = words_df.log_freq.isna()\n",
    "print(f\"{missing_freq.sum()} ({int(missing_freq.mean() * 1000) / 1000}%) words missing frequency values.\")\n",
    "oov_freq = pd.qcut(words_df.log_freq, 50, retbins=True, duplicates=\"drop\")[1][-1]\n",
    "print(f\"Replacing with 2-percentile log-frequency: {oov_freq}\")\n",
    "words_df.loc[missing_freq, \"log_freq\"] = oov_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3fa639-4133-445b-b16e-6afe9dc24835",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83f6ccb8-4cd8-4625-a35e-1c0aae5960f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_phonemizer = english.CMUPhonemizer(cmu_ipa_dict_path)\n",
    "ipa_chars = set(char for word in cmu_phonemizer.mapping.values() for char in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6da50b0e-979c-40b7-a119-24681717885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'əbrivieɪʃən'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB here English \"r\" is transcribed /r/, because it wasn't distinguished in CMU presumably\n",
    "cmu_phonemizer.mapping[\"abbreviation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3d5044d6-46f5-4ca4-b930-285135ef70d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'e', 'o'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ipa_chars = set(char for word in cmu_phonemizer.mapping.values() for char in word)\n",
    "dict_ipa_chars - set(english.ipa_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1943467c-1fc0-4687-aba8-938b10f5910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_PHONEME = \"_\"\n",
    "proc = NaturalLanguageStimulusProcessor(phonemes=list(ipa_chars) + [PAD_PHONEME],\n",
    "                                        hf_model=model,\n",
    "                                        num_candidates=n_candidates,\n",
    "                                        phonemizer=cmu_phonemizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ca6b39bb-2ec0-4326-839d-917cf387c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare proc metadata input.\n",
    "word_to_token = words_df.groupby(\"word_idx\") \\\n",
    "    .apply(lambda x: list(x.token_idx)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3fbf611c-5440-4301-89b4-03df7a9040dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_phonemes = phonemes_df.groupby(\"word_idx\") \\\n",
    "    .apply(lambda xs: list(xs.phoneme)).to_dict()\n",
    "# Convert CMU representation to IPA representation\n",
    "ground_truth_phonemes = {\n",
    "    idx: [english.cmu_ipa_mapping[cmu_phon.upper()] for cmu_phon in cmu_phons]\n",
    "    for idx, cmu_phons in ground_truth_phonemes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fd3c2c28-0ef4-4343-92e3-1257cf9b4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO for words with ground-truth pronunciations in CMUdict, check proportion which\n",
    "# agree with the corpus. Maybe 100% because this is automatic and the forced aligner\n",
    "# draws on Kaldi/CMU reprs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c54bf24b-5713-4650-bf25-ee2532bab3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0, ['t', 'ɛ', 'r', 'ʌ'])),\n",
       " (1, (1, ['s', 't', 'ʊ', 'd'])),\n",
       " (2, (2, ['s', 't', 'ɑ', 'k'])),\n",
       " (3, (3, ['s', 't', 'ɪ', 'l'])),\n",
       " (4, (4, ['w', 'eɪ', 't', 'ɪ', 'ŋ']))]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(range(5), ground_truth_phonemes.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3a4b4407-e3a7-4fa6-837a-473cfda35cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0, tensor([17.5617], dtype=torch.float64))),\n",
       " (1, (1, tensor([15.2065], dtype=torch.float64))),\n",
       " (2, (2, tensor([15.2230], dtype=torch.float64))),\n",
       " (3, (3, tensor([10.2715], dtype=torch.float64))),\n",
       " (4, (4, tensor([12.1730], dtype=torch.float64)))]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare word-level features.\n",
    "word_features = dict(words_df.groupby(\"word_idx\").apply(lambda xs: torch.tensor(xs.iloc[0].log_freq).unsqueeze(0)))\n",
    "list(zip(range(5), word_features.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b6bd8eb5-733a-4346-b193-8c539b8f901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be7584f5764bfc8074dd62a2996d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stim = proc(story_name, tokens, word_to_token, word_features, ground_truth_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "57ddb600-b920-48eb-8c23-5c8771477212",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(output_path).open(\"wb\") as f:\n",
    "    pickle.dump(stim, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
